{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "id": "c-GuGCAWsOjs",
        "outputId": "8ee60876-ec2a-48dd-acea-b6171616b134"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfile은 크게 Data Preparation, Base Model, Add No Finding으로 나뉘어있음\\nDataPreparation은 package import, 나눈 데이터들과 csv를 drive에서 불러오는 과정\\nBase Model은 중권님이 보내줬던 것 그대로 실행\\nAdd No Finding은 여러가지 실험했던 것들\\n    - 실험 한 결과는 csv와 weight로 저장함 (초반 실험은 기록이 안되어있음..)\\n    - 실험 내용\\n        - ForcedBCE어쩌구Loss부분에서 여러가지를 추가하고 빼보면서 결과 기록\\n        - 1 그냥 BCEwithLogitLoss 사용\\n        - 2 MSELoss 사용 -> 쓸데없음\\n        - 3 allzero penalty 추가 (전부 0이 되지는 않게 함) -> 결과 애매 (하지만 논리상 필요)\\n        - 4 nofinding penalty 추가 (nofinding이 1이면 나머지 0이 되게 함) -> 결과 애매 (하지만 논리상 필요)\\n        - 5 focal weight 추가 (imbalanced 상황에서 BCE보완) -> 결과 괜찮게 나옴\\n        - 5.1 focal weight에서 alpha, gamma term이 있는데 이걸 바꿔봄 -> 결과 애매\\n        - 6 class weight 추가 (imbalanced 상황에서 BCE보완) -> 결과 애매\\n        - 7 initial_alpha, initial_beta를 학습 가능하게 바꿈 -> beta가 음수로 가며 결과 엉망. alpha만 학습시킬 땐 학습안됨. 계속 0.1유지.\\n    - bestmodel : allzero penalty, nofinding penalty, focal weight를 loss에 추가한 후 epoch 9번 돌린 모델\\n    \\n    - Dataset, Resnet18 define에선 Nofinding을 label로 추가하는 걸 실행\\n    - DataLoader, Model, Test 안바꿈 (아마도...)\\n    - Train에선 log 기록하는거 말곤 안바꿈 (아마도...)\\nHyperparameter Tuning\\n    - optuna쓰는건데 최종모델에 대해서 돌리겠습니다.\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "\"\"\"\n",
        "file은 크게 Data Preparation, Base Model, Add No Finding으로 나뉘어있음\n",
        "DataPreparation은 package import, 나눈 데이터들과 csv를 drive에서 불러오는 과정\n",
        "Base Model은 중권님이 보내줬던 것 그대로 실행\n",
        "Add No Finding은 여러가지 실험했던 것들\n",
        "    - 실험 한 결과는 csv와 weight로 저장함 (초반 실험은 기록이 안되어있음..)\n",
        "    - 실험 내용\n",
        "        - ForcedBCE어쩌구Loss부분에서 여러가지를 추가하고 빼보면서 결과 기록\n",
        "        - 1 그냥 BCEwithLogitLoss 사용\n",
        "        - 2 MSELoss 사용 -> 쓸데없음\n",
        "        - 3 allzero penalty 추가 (전부 0이 되지는 않게 함) -> 결과 애매 (하지만 논리상 필요)\n",
        "        - 4 nofinding penalty 추가 (nofinding이 1이면 나머지 0이 되게 함) -> 결과 애매 (하지만 논리상 필요)\n",
        "        - 5 focal weight 추가 (imbalanced 상황에서 BCE보완) -> 결과 괜찮게 나옴\n",
        "        - 5.1 focal weight에서 alpha, gamma term이 있는데 이걸 바꿔봄 -> 결과 애매\n",
        "        - 6 class weight 추가 (imbalanced 상황에서 BCE보완) -> 결과 애매\n",
        "        - 7 initial_alpha, initial_beta를 학습 가능하게 바꿈 -> beta가 음수로 가며 결과 엉망. alpha만 학습시킬 땐 학습안됨. 계속 0.1유지.\n",
        "    - bestmodel : allzero penalty, nofinding penalty, focal weight를 loss에 추가한 후 epoch 9번 돌린 모델\n",
        "\n",
        "    - Dataset, Resnet18 define에선 Nofinding을 label로 추가하는 걸 실행\n",
        "    - DataLoader, Model, Test 안바꿈 (아마도...)\n",
        "    - Train에선 log 기록하는거 말곤 안바꿈 (아마도...)\n",
        "Hyperparameter Tuning\n",
        "    - optuna쓰는건데 최종모델에 대해서 돌리겠습니다.\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBrL6ePft0Wd"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "YAUf8QFluBlE"
      },
      "outputs": [],
      "source": [
        "# prompt: drive mount\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import os\n",
        "from PIL import Image\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import random\n",
        "import os\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import torch\n",
        "from sklearn.model_selection import StratifiedShuffleSplit, GroupShuffleSplit\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models import resnet18\n",
        "from torchsummary import summary\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import f1_score\n",
        "import time\n",
        "import os\n",
        "import zipfile\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import f1_score, roc_auc_score\n",
        "\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset, ConcatDataset\n",
        "from torchvision import transforms, datasets, models\n",
        "import urllib.request\n",
        "import tarfile\n",
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image, ImageFilter\n",
        "from tqdm import tqdm\n",
        "\n",
        "import os\n",
        "import urllib.request\n",
        "import threading\n",
        "\n",
        "# 다운로드 받을 경로 설정 (예: 현재 디렉터리 또는 지정된 경로)\n",
        "download_path = 'DATA'  # 원하는 경로로 변경 가능\n",
        "\n",
        "# 다운로드 경로가 존재하지 않으면 생성\n",
        "if not os.path.exists(download_path):\n",
        "    os.makedirs(download_path)\n",
        "\n",
        "# 파일 URL 리스트\n",
        "links = [\n",
        "    'https://nihcc.box.com/shared/static/vfk49d74nhbxq3nqjg0900w5nvkorp5c.gz',\n",
        "    'https://nihcc.box.com/shared/static/i28rlmbvmfjbl8p2n3ril0pptcmcu9d1.gz',\n",
        "    'https://nihcc.box.com/shared/static/f1t00wrtdk94satdfb9olcolqx20z2jp.gz',\n",
        "    'https://nihcc.box.com/shared/static/0aowwzs5lhjrceb3qp67ahp0rd1l1etg.gz',\n",
        "    'https://nihcc.box.com/shared/static/v5e3goj22zr6h8tzualxfsqlqaygfbsn.gz',\n",
        "    'https://nihcc.box.com/shared/static/asi7ikud9jwnkrnkj99jnpfkjdes7l6l.gz',\n",
        "    'https://nihcc.box.com/shared/static/jn1b4mw4n6lnh74ovmcjb8y48h8xj07n.gz',\n",
        "    'https://nihcc.box.com/shared/static/tvpxmn7qyrgl0w8wfh9kqfjskv6nmm1j.gz',\n",
        "    'https://nihcc.box.com/shared/static/upyy3ml7qdumlgk2rfcvlb9k6gvqq2pj.gz',\n",
        "    'https://nihcc.box.com/shared/static/l6nilvfa9cg3s28tqv1qc1olm3gnz54p.gz',\n",
        "    'https://nihcc.box.com/shared/static/hhq8fkdgvcari67vfhs7ppg2w6ni4jze.gz',\n",
        "    'https://nihcc.box.com/shared/static/ioqwiy20ihqwyr8pf4c24eazhh281pbu.gz'\n",
        "]\n",
        "\n",
        "# 파일 다운로드 함수\n",
        "def download_file(url, download_dir, idx):\n",
        "    fn = os.path.join(download_dir, f'images_{idx+1:02d}.tar.gz')\n",
        "    print(f'Downloading {fn}...')\n",
        "    urllib.request.urlretrieve(url, fn)  # 파일 다운로드\n",
        "    print(f'{fn} download complete.')\n",
        "\n",
        "# 다운로드 스레드 생성\n",
        "threads = []\n",
        "for idx, link in enumerate(links):\n",
        "    thread = threading.Thread(target=download_file, args=(link, download_path, idx))\n",
        "    threads.append(thread)\n",
        "    thread.start()\n",
        "\n",
        "# 모든 스레드가 끝날 때까지 기다리기\n",
        "for thread in threads:\n",
        "    thread.join()\n",
        "\n",
        "print(\"All downloads complete. Files are saved in\", download_path)\n",
        "\n",
        "import os\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "# tar 파일들이 저장된 경로 (다운로드 경로와 동일하게 설정)\n",
        "tar_dir = 'DATA'  # 원본 tar 파일들이 저장된 경로\n",
        "extract_dir = 'DATA'  # 압축 해제할 경로\n",
        "\n",
        "# Loop through each downloaded tar file and extract it\n",
        "for idx in range(1, len(links) + 1):\n",
        "    tar_path = os.path.join(tar_dir, f'images_{idx:02d}.tar.gz')\n",
        "\n",
        "    # Extract the tar file into the specified directory\n",
        "    print(f'Extracting {tar_path} to {extract_dir}...')\n",
        "    with tarfile.open(tar_path, 'r:gz') as tar:\n",
        "        tar.extractall(path=extract_dir)\n",
        "\n",
        "    # Delete the original tar.gz file after extraction\n",
        "    os.remove(tar_path)\n",
        "    print(f'Deleted {tar_path} after extraction.')\n",
        "\n",
        "print(\"Extraction complete.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgrThcUIsrc4",
        "outputId": "01ad9313-c4b0-4e50-e8a7-b149d5013c60"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading DATA/images_01.tar.gz...\n",
            "Downloading DATA/images_02.tar.gz...\n",
            "Downloading DATA/images_03.tar.gz...\n",
            "Downloading DATA/images_04.tar.gz...\n",
            "Downloading DATA/images_05.tar.gz...\n",
            "Downloading DATA/images_06.tar.gz...\n",
            "Downloading DATA/images_07.tar.gz...\n",
            "Downloading DATA/images_08.tar.gz...\n",
            "Downloading DATA/images_09.tar.gz...\n",
            "Downloading DATA/images_10.tar.gz...\n",
            "Downloading DATA/images_11.tar.gz...\n",
            "Downloading DATA/images_12.tar.gz...\n",
            "DATA/images_01.tar.gz download complete.\n",
            "DATA/images_12.tar.gz download complete.\n",
            "DATA/images_02.tar.gz download complete.\n",
            "DATA/images_05.tar.gz download complete.\n",
            "DATA/images_04.tar.gz download complete.\n",
            "DATA/images_03.tar.gz download complete.\n",
            "DATA/images_07.tar.gz download complete.\n",
            "DATA/images_08.tar.gz download complete.\n",
            "DATA/images_06.tar.gz download complete.\n",
            "DATA/images_09.tar.gz download complete.\n",
            "DATA/images_10.tar.gz download complete.\n",
            "DATA/images_11.tar.gz download complete.\n",
            "All downloads complete. Files are saved in DATA\n",
            "Extracting DATA/images_01.tar.gz to DATA...\n",
            "Deleted DATA/images_01.tar.gz after extraction.\n",
            "Extracting DATA/images_02.tar.gz to DATA...\n",
            "Deleted DATA/images_02.tar.gz after extraction.\n",
            "Extracting DATA/images_03.tar.gz to DATA...\n",
            "Deleted DATA/images_03.tar.gz after extraction.\n",
            "Extracting DATA/images_04.tar.gz to DATA...\n",
            "Deleted DATA/images_04.tar.gz after extraction.\n",
            "Extracting DATA/images_05.tar.gz to DATA...\n",
            "Deleted DATA/images_05.tar.gz after extraction.\n",
            "Extracting DATA/images_06.tar.gz to DATA...\n",
            "Deleted DATA/images_06.tar.gz after extraction.\n",
            "Extracting DATA/images_07.tar.gz to DATA...\n",
            "Deleted DATA/images_07.tar.gz after extraction.\n",
            "Extracting DATA/images_08.tar.gz to DATA...\n",
            "Deleted DATA/images_08.tar.gz after extraction.\n",
            "Extracting DATA/images_09.tar.gz to DATA...\n",
            "Deleted DATA/images_09.tar.gz after extraction.\n",
            "Extracting DATA/images_10.tar.gz to DATA...\n",
            "Deleted DATA/images_10.tar.gz after extraction.\n",
            "Extracting DATA/images_11.tar.gz to DATA...\n",
            "Deleted DATA/images_11.tar.gz after extraction.\n",
            "Extracting DATA/images_12.tar.gz to DATA...\n",
            "Deleted DATA/images_12.tar.gz after extraction.\n",
            "Extraction complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datapath = \"./DATA/images\""
      ],
      "metadata": {
        "id": "qXcV4XADs9qC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lr0oOqRht5Fs"
      },
      "source": [
        "## Dataset, Resnet18 define"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdIIonR5zjSn",
        "outputId": "f98ed6ed-327c-4916-e660-f3dc22fb7503"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ],
      "source": [
        "print(torch.cuda.current_device())\n",
        "\n",
        "def get_labels(diseases):\n",
        "    labels = torch.zeros(len(class_names))\n",
        "    if diseases != 'No Finding':\n",
        "        for label_name in diseases.split('|'):\n",
        "            if label_name in class_names:\n",
        "                labels[class_names.index(label_name)] = 1\n",
        "    return labels\n",
        "\n",
        "class CXR14dataset(Dataset):\n",
        "    def __init__(self, img_dirs, df, augment=None):\n",
        "        self.img_dirs = img_dirs\n",
        "        self.df = df\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.5123], [0.2307])\n",
        "        ])\n",
        "        self.augment = augment\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.df.iloc[idx, 0]\n",
        "        diseases = self.df.iloc[idx, 1]\n",
        "        label = get_labels(diseases)\n",
        "\n",
        "        image = None\n",
        "        for img_dir in self.img_dirs:\n",
        "            img_path = os.path.join(img_dir, img_name)\n",
        "            if os.path.exists(img_path):\n",
        "                image = Image.open(img_path).convert(\"RGB\")\n",
        "                break\n",
        "\n",
        "        if image is None:\n",
        "            raise FileNotFoundError(f\"Image {img_name} not found in provided directories.\")\n",
        "\n",
        "        if self.augment:\n",
        "            image = self.augment(image)\n",
        "        else:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "class CustomResNet18(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(CustomResNet18, self).__init__()\n",
        "\n",
        "        resnet = resnet18(weights=\"IMAGENET1K_V1\")  # Always use pretrained weights\n",
        "        self.conv1 = resnet.conv1\n",
        "        self.bn1 = resnet.bn1\n",
        "        self.relu = resnet.relu\n",
        "        self.maxpool = resnet.maxpool\n",
        "        self.layer1 = resnet.layer1\n",
        "        self.layer2 = resnet.layer2\n",
        "        self.layer3 = resnet.layer3\n",
        "        self.layer4 = resnet.layer4\n",
        "        self.avgpool = resnet.avgpool\n",
        "\n",
        "        self.dropout1 = nn.Dropout(p=0.3)\n",
        "        self.dropout2 = nn.Dropout(p=0.4)\n",
        "        self.dropout3 = nn.Dropout(p=0.4)\n",
        "        self.dropout4 = nn.Dropout(p=0.5)\n",
        "\n",
        "        self.fc = nn.Linear(512, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x = self.layer2(x)\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        x = self.layer3(x)\n",
        "        x = self.dropout3(x)\n",
        "\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.dropout4(x)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QT5fKb_zuCAx"
      },
      "source": [
        "## DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbQH-Gzi0x7C",
        "outputId": "b59c6c10-bc0f-4f8f-f1ea-c358c82527b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Atelectasis', 'Consolidation', 'Effusion', 'Infiltration', 'Mass', 'Nodule', 'Pneumothorax']\n",
            "Train data: (53388, 12)\n",
            "Validation data: (6700, 12)\n",
            "Test data: (6701, 12)\n",
            "torch.Size([64, 3, 224, 224])\n",
            "torch.Size([64, 7])\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import random\n",
        "import os\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import torch\n",
        "from sklearn.model_selection import StratifiedShuffleSplit, GroupShuffleSplit\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "csv_file_path = './Data_Entry_2017_v2020.csv'\n",
        "\n",
        "df = pd.read_csv(csv_file_path)\n",
        "\n",
        "\n",
        "class_names = ['Atelectasis',  'Consolidation',  'Effusion',\n",
        "                 'Infiltration', 'Mass', 'Nodule', 'Pneumothorax'\n",
        "                #'Pleural_Thickening',\n",
        "               #'Hernia',\n",
        "               # 'Pneumonia',\n",
        "               # 'Fibrosis',\n",
        "               #  'Edema',\n",
        "               # 'Cardiomegaly',\n",
        "               # 'Emphysema',\n",
        "            ]\n",
        "\n",
        "def get_labels(diseases):\n",
        "    labels = torch.zeros(len(class_names))\n",
        "    if diseases != 'No Finding':\n",
        "        for label_name in diseases.split('|'):\n",
        "            if label_name in class_names:\n",
        "                labels[class_names.index(label_name)] = 1\n",
        "    return labels\n",
        "\n",
        "class CXR14dataset(Dataset):\n",
        "    def __init__(self, img_dirs, df, augment=None):\n",
        "        self.img_dirs = img_dirs\n",
        "        self.df = df\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.5123], [0.2307])\n",
        "        ])\n",
        "        self.augment = augment\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.df.iloc[idx, 0]\n",
        "        diseases = self.df.iloc[idx, 1]\n",
        "        label = get_labels(diseases)\n",
        "\n",
        "        image = None\n",
        "        for img_dir in self.img_dirs:\n",
        "            img_path = os.path.join(img_dir, img_name)\n",
        "            if os.path.exists(img_path):\n",
        "                image = Image.open(img_path).convert(\"RGB\")\n",
        "                break\n",
        "\n",
        "        if image is None:\n",
        "            raise FileNotFoundError(f\"Image {img_name} not found in provided directories.\")\n",
        "\n",
        "        if self.augment:\n",
        "            image = self.augment(image)\n",
        "        else:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "img_dirs = ['./DATA/images']\n",
        "\n",
        "# 데이터셋을 train, validation, test로 나누기 (Stratified Split을 사용하여 클래스 비율 유지)\n",
        "# 모든 질병 컬럼을 하나의 벡터로 결합하여 분할 (멀티 라벨 문제에 대한 처리)\n",
        "df['combined_labels'] = df['Finding Labels'].apply(\n",
        "    lambda x: '|'.join(sorted([label for label in x.split('|') if label in class_names]))\n",
        ")\n",
        "\n",
        "sampling_ratios = {\n",
        "    'Atelectasis': 1,\n",
        "    'Cardiomegaly': 1,\n",
        "    'Consolidation': 1,\n",
        "    #'Edema': 1,\n",
        "    'Effusion': 1,\n",
        "    'Emphysema': 1,\n",
        "    #'Fibrosis': 1,\n",
        "    #'Hernia': 1,\n",
        "    'Infiltration': 1,\n",
        "    'Mass': 1,\n",
        "    'Nodule': 1,\n",
        "    #'Pneumonia': 1,\n",
        "    'Pleural_Thickening': 1,\n",
        "    'Pneumothorax': 1,\n",
        "    'No Finding': 0.6\n",
        "}\n",
        "\n",
        "def apply_class_sampling(df, class_names, sampling_ratios):\n",
        "    sampled_df = pd.DataFrame()\n",
        "    for class_name in class_names:\n",
        "        if class_name == 'No Finding':\n",
        "            no_finding_df = df[df['Finding Labels'] == 'No Finding']\n",
        "            sample_size = int(len(no_finding_df) * sampling_ratios[class_name])\n",
        "            sampled_no_finding_df = no_finding_df.sample(n=sample_size, random_state=42)\n",
        "            sampled_df = pd.concat([sampled_df, sampled_no_finding_df], axis=0)\n",
        "        else:\n",
        "            class_df = df[df['Finding Labels'].str.contains(class_name)]\n",
        "            sample_size = int(len(class_df) * sampling_ratios[class_name])\n",
        "            sampled_class_df = class_df.sample(n=sample_size, random_state=42)\n",
        "            sampled_df = pd.concat([sampled_df, sampled_class_df], axis=0)\n",
        "    return sampled_df\n",
        "\n",
        "class_names_nf = class_names + ['No Finding']\n",
        "print(class_names)\n",
        "\n",
        "df_sampled = apply_class_sampling(df, class_names, sampling_ratios)\n",
        "\n",
        "class_counts = df_sampled['combined_labels'].value_counts()\n",
        "\n",
        "rare_classes = class_counts[class_counts < 10].index\n",
        "\n",
        "df_filtered = df_sampled[~df_sampled['combined_labels'].isin(rare_classes)]\n",
        "\n",
        "# train_df, temp_df = train_test_split(df_filtered, test_size=0.2, stratify=df_filtered['combined_labels'], random_state=42)\n",
        "# valid_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['combined_labels'], random_state=42)\n",
        "\n",
        "\n",
        "group_split = GroupShuffleSplit(test_size=0.2, n_splits=1, random_state=42)\n",
        "train_indices, temp_indices = next(group_split.split(df_filtered, groups=df_filtered['Patient ID']))\n",
        "train_df = df_filtered.iloc[train_indices]\n",
        "temp_df = df_filtered.iloc[temp_indices]\n",
        "\n",
        "stratified_split = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=42)\n",
        "\n",
        "for valid_indices, test_indices in stratified_split.split(temp_df, temp_df['combined_labels']):\n",
        "    valid_df = temp_df.iloc[valid_indices]\n",
        "    test_df = temp_df.iloc[test_indices]\n",
        "\n",
        "print(f\"Train data: {train_df.shape}\")\n",
        "print(f\"Validation data: {valid_df.shape}\")\n",
        "print(f\"Test data: {test_df.shape}\")\n",
        "\n",
        "\n",
        "batch_size = 64\n",
        "num_cores = os.cpu_count()\n",
        "train_dataset = CXR14dataset(img_dirs=img_dirs, df=train_df)\n",
        "valid_dataset = CXR14dataset(img_dirs=img_dirs, df=valid_df)\n",
        "test_dataset = CXR14dataset(img_dirs=img_dirs, df=test_df)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_cores, pin_memory=True, persistent_workers=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=num_cores, pin_memory=True, persistent_workers=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_cores, pin_memory=True, persistent_workers=True)\n",
        "\n",
        "\n",
        "for images, labels in train_loader:\n",
        "    print(images.shape)\n",
        "    print(labels.shape)\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpvgSGByw5dd"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "SOZ0Xwb3u6Ut",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a468da8-e78d-48af-9d6a-669c5bca7f5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
            "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
            "              ReLU-7           [-1, 64, 56, 56]               0\n",
            "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
            "             ReLU-10           [-1, 64, 56, 56]               0\n",
            "       BasicBlock-11           [-1, 64, 56, 56]               0\n",
            "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
            "             ReLU-14           [-1, 64, 56, 56]               0\n",
            "           Conv2d-15           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
            "             ReLU-17           [-1, 64, 56, 56]               0\n",
            "       BasicBlock-18           [-1, 64, 56, 56]               0\n",
            "          Dropout-19           [-1, 64, 56, 56]               0\n",
            "           Conv2d-20          [-1, 128, 28, 28]          73,728\n",
            "      BatchNorm2d-21          [-1, 128, 28, 28]             256\n",
            "             ReLU-22          [-1, 128, 28, 28]               0\n",
            "           Conv2d-23          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-24          [-1, 128, 28, 28]             256\n",
            "           Conv2d-25          [-1, 128, 28, 28]           8,192\n",
            "      BatchNorm2d-26          [-1, 128, 28, 28]             256\n",
            "             ReLU-27          [-1, 128, 28, 28]               0\n",
            "       BasicBlock-28          [-1, 128, 28, 28]               0\n",
            "           Conv2d-29          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-30          [-1, 128, 28, 28]             256\n",
            "             ReLU-31          [-1, 128, 28, 28]               0\n",
            "           Conv2d-32          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-33          [-1, 128, 28, 28]             256\n",
            "             ReLU-34          [-1, 128, 28, 28]               0\n",
            "       BasicBlock-35          [-1, 128, 28, 28]               0\n",
            "          Dropout-36          [-1, 128, 28, 28]               0\n",
            "           Conv2d-37          [-1, 256, 14, 14]         294,912\n",
            "      BatchNorm2d-38          [-1, 256, 14, 14]             512\n",
            "             ReLU-39          [-1, 256, 14, 14]               0\n",
            "           Conv2d-40          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-41          [-1, 256, 14, 14]             512\n",
            "           Conv2d-42          [-1, 256, 14, 14]          32,768\n",
            "      BatchNorm2d-43          [-1, 256, 14, 14]             512\n",
            "             ReLU-44          [-1, 256, 14, 14]               0\n",
            "       BasicBlock-45          [-1, 256, 14, 14]               0\n",
            "           Conv2d-46          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-47          [-1, 256, 14, 14]             512\n",
            "             ReLU-48          [-1, 256, 14, 14]               0\n",
            "           Conv2d-49          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-50          [-1, 256, 14, 14]             512\n",
            "             ReLU-51          [-1, 256, 14, 14]               0\n",
            "       BasicBlock-52          [-1, 256, 14, 14]               0\n",
            "          Dropout-53          [-1, 256, 14, 14]               0\n",
            "           Conv2d-54            [-1, 512, 7, 7]       1,179,648\n",
            "      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-56            [-1, 512, 7, 7]               0\n",
            "           Conv2d-57            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-58            [-1, 512, 7, 7]           1,024\n",
            "           Conv2d-59            [-1, 512, 7, 7]         131,072\n",
            "      BatchNorm2d-60            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-61            [-1, 512, 7, 7]               0\n",
            "       BasicBlock-62            [-1, 512, 7, 7]               0\n",
            "           Conv2d-63            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-65            [-1, 512, 7, 7]               0\n",
            "           Conv2d-66            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-67            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-68            [-1, 512, 7, 7]               0\n",
            "       BasicBlock-69            [-1, 512, 7, 7]               0\n",
            "AdaptiveAvgPool2d-70            [-1, 512, 1, 1]               0\n",
            "          Dropout-71                  [-1, 512]               0\n",
            "           Linear-72                    [-1, 7]           3,591\n",
            "================================================================\n",
            "Total params: 11,180,103\n",
            "Trainable params: 11,180,103\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 65.47\n",
            "Params size (MB): 42.65\n",
            "Estimated Total Size (MB): 108.69\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "num_classes = len(class_names)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = CustomResNet18(num_classes=num_classes).to(device)\n",
        "\n",
        "input_size = (3, 224, 224)\n",
        "summary(model, input_size=input_size, device=device.type)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5z_Kg7GyPqI"
      },
      "source": [
        "# Force at least one class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWovSSZryvJE"
      },
      "source": [
        "## Dataset, Resnet18 define"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duZn5FYdyT-d",
        "outputId": "10345977-4bd9-44bc-948a-13aecf67b48b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ],
      "source": [
        "print(torch.cuda.current_device())\n",
        "\n",
        "# Add No findings\n",
        "def get_labels(diseases):\n",
        "    labels = torch.zeros(len(class_names))\n",
        "    for label_name in diseases.split('|'):\n",
        "        if label_name in class_names:\n",
        "            labels[class_names.index(label_name)] = 1\n",
        "    return labels\n",
        "\n",
        "class CXR14dataset(Dataset):\n",
        "    def __init__(self, img_dirs, df, augment=None):\n",
        "        self.img_dirs = img_dirs\n",
        "        self.df = df\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.5123], [0.2307])\n",
        "        ])\n",
        "        self.augment = augment\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.df.iloc[idx, 0]\n",
        "        diseases = self.df.iloc[idx, 1]\n",
        "        label = get_labels(diseases)\n",
        "\n",
        "        image = None\n",
        "        for img_dir in self.img_dirs:\n",
        "            img_path = os.path.join(img_dir, img_name)\n",
        "            if os.path.exists(img_path):\n",
        "                image = Image.open(img_path).convert(\"RGB\")\n",
        "                break\n",
        "\n",
        "        if image is None:\n",
        "            raise FileNotFoundError(f\"Image {img_name} not found in provided directories.\")\n",
        "\n",
        "        if self.augment:\n",
        "            image = self.augment(image)\n",
        "        else:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "class CustomResNet18(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(CustomResNet18, self).__init__()\n",
        "\n",
        "        resnet = resnet18(weights=\"IMAGENET1K_V1\")  # Always use pretrained weights\n",
        "        self.conv1 = resnet.conv1\n",
        "        self.bn1 = resnet.bn1\n",
        "        self.relu = resnet.relu\n",
        "        self.maxpool = resnet.maxpool\n",
        "        self.layer1 = resnet.layer1\n",
        "        self.layer2 = resnet.layer2\n",
        "        self.layer3 = resnet.layer3\n",
        "        self.layer4 = resnet.layer4\n",
        "        self.avgpool = resnet.avgpool\n",
        "\n",
        "        self.dropout1 = nn.Dropout(p=0.3)\n",
        "        self.dropout2 = nn.Dropout(p=0.4)\n",
        "        self.dropout3 = nn.Dropout(p=0.4)\n",
        "        self.dropout4 = nn.Dropout(p=0.5)\n",
        "\n",
        "        self.fc = nn.Linear(512, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x = self.layer2(x)\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        x = self.layer3(x)\n",
        "        x = self.dropout3(x)\n",
        "\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.dropout4(x)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpCEP5xTyy6J"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "collapsed": true,
        "id": "lelcdvS9yziq"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = CustomResNet18(num_classes=num_classes).to(device)\n",
        "\n",
        "#input_size = (3, 224, 224)\n",
        "#summary(model, input_size=input_size, device=device.type)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "2qSohvJpXink",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 656
        },
        "outputId": "1af354c0-335d-410a-e854-6e650604b6db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-53-35b5eda21df0>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train_df['combined_labels'].fillna(\"No Finding\", inplace=True)\n",
            "<ipython-input-53-35b5eda21df0>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  valid_df['combined_labels'].fillna(\"No Finding\", inplace=True)\n",
            "<ipython-input-53-35b5eda21df0>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_df['combined_labels'].fillna(\"No Finding\", inplace=True)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1800x600 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train_df['combined_labels'].fillna(\"No Finding\", inplace=True)\n",
        "valid_df['combined_labels'].fillna(\"No Finding\", inplace=True)\n",
        "test_df['combined_labels'].fillna(\"No Finding\", inplace=True)\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "train_class_counts = train_df['combined_labels'].str.split('|', expand=True).stack().value_counts()\n",
        "valid_class_counts = valid_df['combined_labels'].str.split('|', expand=True).stack().value_counts()\n",
        "test_class_counts = test_df['combined_labels'].str.split('|', expand=True).stack().value_counts()\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "sns.barplot(x=train_class_counts.index, y=train_class_counts.values/train_class_counts.sum(), palette='viridis', ax=axes[0])\n",
        "axes[0].set_title('Train Class Distribution')\n",
        "axes[0].set_xlabel('Class')\n",
        "axes[0].set_ylabel('Frequency')\n",
        "axes[0].tick_params(axis='x', rotation=90)\n",
        "\n",
        "sns.barplot(x=valid_class_counts.index, y=valid_class_counts.values/valid_class_counts.sum(), palette='viridis', ax=axes[1])\n",
        "axes[1].set_title('Validation Class Distribution')\n",
        "axes[1].set_xlabel('Class')\n",
        "axes[1].set_ylabel('Frequency')\n",
        "axes[1].tick_params(axis='x', rotation=90)\n",
        "\n",
        "sns.barplot(x=test_class_counts.index, y=test_class_counts.values/test_class_counts.sum(), palette='viridis', ax=axes[2])\n",
        "axes[2].set_title('Test Class Distribution')\n",
        "axes[2].set_xlabel('Class')\n",
        "axes[2].set_ylabel('Frequency')\n",
        "axes[2].tick_params(axis='x', rotation=90)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "id": "T6fOGJ66RDfl",
        "outputId": "66609b97-f1b3-468e-d9c3-fa17f155d2bb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Infiltration      3.715659\n",
              "Effusion          4.775730\n",
              "Atelectasis       5.564464\n",
              "Nodule           10.675949\n",
              "Mass             10.769057\n",
              "Consolidation    12.325642\n",
              "Pneumothorax     13.494181\n",
              "Name: count, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Infiltration</th>\n",
              "      <td>3.715659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Effusion</th>\n",
              "      <td>4.775730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Atelectasis</th>\n",
              "      <td>5.564464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nodule</th>\n",
              "      <td>10.675949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mass</th>\n",
              "      <td>10.769057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Consolidation</th>\n",
              "      <td>12.325642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pneumothorax</th>\n",
              "      <td>13.494181</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "one_over_tcc = train_class_counts.sum() / train_class_counts\n",
        "one_over_tcc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "id": "xPAHY7heXV__",
        "outputId": "26931250-802c-4f77-d592-0afccf807de5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Infiltration     0.424157\n",
              "Effusion         0.545169\n",
              "Atelectasis      0.635206\n",
              "Nodule           1.218702\n",
              "Mass             1.229331\n",
              "Consolidation    1.407021\n",
              "Pneumothorax     1.540415\n",
              "Name: count, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Infiltration</th>\n",
              "      <td>0.424157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Effusion</th>\n",
              "      <td>0.545169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Atelectasis</th>\n",
              "      <td>0.635206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nodule</th>\n",
              "      <td>1.218702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mass</th>\n",
              "      <td>1.229331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Consolidation</th>\n",
              "      <td>1.407021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pneumothorax</th>\n",
              "      <td>1.540415</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "one_over_tcc = one_over_tcc / one_over_tcc.mean()\n",
        "one_over_tcc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4Pn8gyhYw9t",
        "outputId": "cf20c9ad-e9ac-4ff9-bed2-09003d69a22f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.64, 1.41, 0.55, 0.42, 1.23, 1.22, 1.54]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "class_weights = [np.round(one_over_tcc.loc[x],2) for x in class_names]\n",
        "class_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "yoLuHpHA0GEv"
      },
      "outputs": [],
      "source": [
        "class ForcedBCEWithLogitsLoss(nn.Module):\n",
        "    def __init__(self, reduction='mean', initial_alpha=0.1, initial_beta=0.1, gamma_neg=4, gamma_pos=1, class_weights=class_weights):\n",
        "        super(ForcedBCEWithLogitsLoss, self).__init__()\n",
        "        self.bce_loss = nn.BCEWithLogitsLoss(reduction=reduction, weight= None) #torch.tensor(class_weights))\n",
        "        self.initial_alpha = initial_alpha\n",
        "        #self.alpha = nn.Parameter(torch.tensor(initial_alpha, dtype=torch.float32))  # Learnable parameter\n",
        "        self.initial_beta = initial_beta\n",
        "        # self.beta = nn.Parameter(torch.tensor(initial_beta, dtype=torch.float32))  # Learnable parameter\n",
        "        self.mse_loss = nn.MSELoss()\n",
        "        self.gamma_neg = gamma_neg\n",
        "        self.gamma_pos = gamma_pos\n",
        "        #self.class_weight = class_weight\n",
        "\n",
        "    def forward(self, logits, targets):\n",
        "\n",
        "        ## BCEWithLogitsLoss\n",
        "        bce_loss = self.bce_loss(logits, targets)\n",
        "\n",
        "\n",
        "        ## class probabilities\n",
        "        probs = torch.sigmoid(logits)\n",
        "\n",
        "\n",
        "        ## MSELoss\n",
        "        # mse_loss = self.mse_loss(probs, targets)\n",
        "\n",
        "        ## Focal asymmetric Loss\n",
        "        p_t = probs * targets + (1 - probs) * (1 - targets)   # 맞은 거의 맞은 확률 + 틀린 거의 틀린 확률\n",
        "        #gamma = self.gamma_pos * targets + self.gamma_neg * (1 - targets) #\n",
        "        gamma = 2\n",
        "        focal_weight = torch.mean((1 - p_t).pow(gamma))\n",
        "\n",
        "\n",
        "\n",
        "        ## All-Zero penalty\n",
        "        \"\"\"\n",
        "        # Regularization term: encourage at least one class to be close to 1 for each sample\n",
        "        max_probs = torch.max(probs, dim=1).values  # Max probability for each sample\n",
        "        reg_loss =  1 - max_probs  # Regularization term encourages max_probs to be close to 1\n",
        "        \"\"\"\n",
        "        zero_predictions = (probs.sum(dim=1) == 0).float()  # Rows where sum is 0\n",
        "        zero_penalty = zero_predictions.sum()  # Count rows with all zeros\n",
        "\n",
        "\n",
        "        ## Exclusive No Finding penalty\n",
        "        last_label_probs = probs[:, -1]  # Last column (last predicted label)\n",
        "        preceding_probs = probs[:, :-1]  # All columns except the last one\n",
        "\n",
        "        # Penalize if preceding values are not close to 0 when last_label is close to 1\n",
        "        penalty = torch.sum(preceding_probs * last_label_probs.unsqueeze(1))\n",
        "\n",
        "\n",
        "        # Combine BCE loss with the regularization term\n",
        "        total_loss = bce_loss + self.initial_alpha * zero_penalty / logits.size(0) + self.initial_beta * penalty / logits.size(0)\n",
        "\n",
        "        return total_loss\n",
        "\n",
        "criterion = ForcedBCEWithLogitsLoss()\n",
        "\n",
        "criterion = criterion.to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "#optimizer = optim.Adam(list(model.parameters()) + [criterion.alpha], lr=1e-3)\n",
        "\n",
        "\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjFohFrD17Mt"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Akxrx1Xd18ZY",
        "outputId": "a00ed020-39d7-4303-fac1-925a08fe9917"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/20: 100%|██████████| 835/835 [02:41<00:00,  5.18batch/s]\n",
            "Validating Epoch 1/20: 100%|██████████| 105/105 [00:20<00:00,  5.02batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model saved with F1: 0.2563\n",
            "Epoch 1/20\n",
            "Train Loss: 0.5045, Train Accuracy: 0.1317\n",
            "Valid Loss: 0.5046, Valid Accuracy: 0.1991\n",
            "Validation F1 Score: 0.2563\n",
            "===============================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/20: 100%|██████████| 835/835 [02:43<00:00,  5.11batch/s]\n",
            "Validating Epoch 2/20: 100%|██████████| 105/105 [00:20<00:00,  5.21batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model saved with F1: 0.2970\n",
            "Epoch 2/20\n",
            "Train Loss: 0.4734, Train Accuracy: 0.1703\n",
            "Valid Loss: 0.4874, Valid Accuracy: 0.1800\n",
            "Validation F1 Score: 0.2970\n",
            "===============================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/20: 100%|██████████| 835/835 [02:43<00:00,  5.12batch/s]\n",
            "Validating Epoch 3/20: 100%|██████████| 105/105 [00:19<00:00,  5.27batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model saved with F1: 0.3027\n",
            "Epoch 3/20\n",
            "Train Loss: 0.4561, Train Accuracy: 0.1923\n",
            "Valid Loss: 0.5035, Valid Accuracy: 0.1919\n",
            "Validation F1 Score: 0.3027\n",
            "===============================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/20: 100%|██████████| 835/835 [02:43<00:00,  5.11batch/s]\n",
            "Validating Epoch 4/20: 100%|██████████| 105/105 [00:19<00:00,  5.26batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model saved with F1: 0.3543\n",
            "Epoch 4/20\n",
            "Train Loss: 0.4409, Train Accuracy: 0.2073\n",
            "Valid Loss: 0.4730, Valid Accuracy: 0.2024\n",
            "Validation F1 Score: 0.3543\n",
            "===============================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/20: 100%|██████████| 835/835 [02:43<00:00,  5.11batch/s]\n",
            "Validating Epoch 5/20: 100%|██████████| 105/105 [00:19<00:00,  5.28batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model saved with F1: 0.3649\n",
            "Epoch 5/20\n",
            "Train Loss: 0.4178, Train Accuracy: 0.2272\n",
            "Valid Loss: 0.4905, Valid Accuracy: 0.2085\n",
            "Validation F1 Score: 0.3649\n",
            "===============================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/20: 100%|██████████| 835/835 [02:43<00:00,  5.10batch/s]\n",
            "Validating Epoch 6/20: 100%|██████████| 105/105 [00:20<00:00,  5.15batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model saved with F1: 0.3832\n",
            "Epoch 6/20\n",
            "Train Loss: 0.3909, Train Accuracy: 0.2580\n",
            "Valid Loss: 0.5060, Valid Accuracy: 0.1772\n",
            "Validation F1 Score: 0.3832\n",
            "===============================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/20: 100%|██████████| 835/835 [02:43<00:00,  5.11batch/s]\n",
            "Validating Epoch 7/20: 100%|██████████| 105/105 [00:19<00:00,  5.26batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model saved with F1: 0.3895\n",
            "Epoch 7/20\n",
            "Train Loss: 0.3554, Train Accuracy: 0.3002\n",
            "Valid Loss: 0.5492, Valid Accuracy: 0.2039\n",
            "Validation F1 Score: 0.3895\n",
            "===============================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/20: 100%|██████████| 835/835 [02:43<00:00,  5.11batch/s]\n",
            "Validating Epoch 8/20: 100%|██████████| 105/105 [00:19<00:00,  5.28batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/20\n",
            "Train Loss: 0.3131, Train Accuracy: 0.3682\n",
            "Valid Loss: 0.5693, Valid Accuracy: 0.1978\n",
            "Validation F1 Score: 0.3829\n",
            "===============================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/20: 100%|██████████| 835/835 [02:43<00:00,  5.11batch/s]\n",
            "Validating Epoch 9/20: 100%|██████████| 105/105 [00:20<00:00,  5.21batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model saved with F1: 0.4145\n",
            "Epoch 9/20\n",
            "Train Loss: 0.2698, Train Accuracy: 0.4438\n",
            "Valid Loss: 0.6198, Valid Accuracy: 0.1857\n",
            "Validation F1 Score: 0.4145\n",
            "===============================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/20: 100%|██████████| 835/835 [02:43<00:00,  5.11batch/s]\n",
            "Validating Epoch 10/20: 100%|██████████| 105/105 [00:19<00:00,  5.25batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model saved with F1: 0.4236\n",
            "Epoch 10/20\n",
            "Train Loss: 0.2306, Train Accuracy: 0.5158\n",
            "Valid Loss: 0.6662, Valid Accuracy: 0.1834\n",
            "Validation F1 Score: 0.4236\n",
            "===============================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/20: 100%|██████████| 835/835 [02:43<00:00,  5.11batch/s]\n",
            "Validating Epoch 11/20: 100%|██████████| 105/105 [00:19<00:00,  5.26batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/20\n",
            "Train Loss: 0.1972, Train Accuracy: 0.5844\n",
            "Valid Loss: 0.7454, Valid Accuracy: 0.1852\n",
            "Validation F1 Score: 0.4064\n",
            "===============================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/20: 100%|██████████| 835/835 [02:43<00:00,  5.11batch/s]\n",
            "Validating Epoch 12/20: 100%|██████████| 105/105 [00:19<00:00,  5.26batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/20\n",
            "Train Loss: 0.1695, Train Accuracy: 0.6373\n",
            "Valid Loss: 0.8416, Valid Accuracy: 0.1939\n",
            "Validation F1 Score: 0.3646\n",
            "===============================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/20: 100%|██████████| 835/835 [02:43<00:00,  5.11batch/s]\n",
            "Validating Epoch 13/20: 100%|██████████| 105/105 [00:20<00:00,  5.24batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/20\n",
            "Train Loss: 0.1490, Train Accuracy: 0.6846\n",
            "Valid Loss: 0.8702, Valid Accuracy: 0.1815\n",
            "Validation F1 Score: 0.4066\n",
            "===============================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/20: 100%|██████████| 835/835 [02:43<00:00,  5.10batch/s]\n",
            "Validating Epoch 14/20: 100%|██████████| 105/105 [00:19<00:00,  5.25batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/20\n",
            "Train Loss: 0.1320, Train Accuracy: 0.7232\n",
            "Valid Loss: 0.8993, Valid Accuracy: 0.1848\n",
            "Validation F1 Score: 0.3819\n",
            "===============================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/20: 100%|██████████| 835/835 [02:43<00:00,  5.11batch/s]\n",
            "Validating Epoch 15/20: 100%|██████████| 105/105 [00:20<00:00,  5.15batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/20\n",
            "Train Loss: 0.1182, Train Accuracy: 0.7480\n",
            "Valid Loss: 1.0185, Valid Accuracy: 0.1885\n",
            "Validation F1 Score: 0.3741\n",
            "===============================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/20: 100%|██████████| 835/835 [02:43<00:00,  5.10batch/s]\n",
            "Validating Epoch 16/20: 100%|██████████| 105/105 [00:20<00:00,  5.24batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/20\n",
            "Train Loss: 0.1066, Train Accuracy: 0.7759\n",
            "Valid Loss: 1.0629, Valid Accuracy: 0.1766\n",
            "Validation F1 Score: 0.3712\n",
            "===============================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/20: 100%|██████████| 835/835 [02:43<00:00,  5.09batch/s]\n",
            "Validating Epoch 17/20: 100%|██████████| 105/105 [00:19<00:00,  5.28batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/20\n",
            "Train Loss: 0.0980, Train Accuracy: 0.7976\n",
            "Valid Loss: 1.0838, Valid Accuracy: 0.1891\n",
            "Validation F1 Score: 0.3765\n",
            "===============================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/20: 100%|██████████| 835/835 [02:42<00:00,  5.13batch/s]\n",
            "Validating Epoch 18/20: 100%|██████████| 105/105 [00:19<00:00,  5.30batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/20\n",
            "Train Loss: 0.0914, Train Accuracy: 0.8122\n",
            "Valid Loss: 1.0966, Valid Accuracy: 0.1851\n",
            "Validation F1 Score: 0.3745\n",
            "===============================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/20: 100%|██████████| 835/835 [02:43<00:00,  5.11batch/s]\n",
            "Validating Epoch 19/20: 100%|██████████| 105/105 [00:20<00:00,  5.23batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/20\n",
            "Train Loss: 0.0852, Train Accuracy: 0.8284\n",
            "Valid Loss: 1.1455, Valid Accuracy: 0.1801\n",
            "Validation F1 Score: 0.3661\n",
            "===============================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/20: 100%|██████████| 835/835 [02:42<00:00,  5.13batch/s]\n",
            "Validating Epoch 20/20: 100%|██████████| 105/105 [00:20<00:00,  5.22batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/20\n",
            "Train Loss: 0.0797, Train Accuracy: 0.8375\n",
            "Valid Loss: 1.1994, Valid Accuracy: 0.1845\n",
            "Validation F1 Score: 0.3566\n",
            "===============================\n"
          ]
        }
      ],
      "source": [
        "TITLE = \"az_nf_focal_classw2\" # allzero, learnable alpha\n",
        "\n",
        "num_epochs = 20\n",
        "best_valid_f1 = 0.0\n",
        "save_path = \"best_model.pth\"\n",
        "\n",
        "output_folder = f\"/content/training_{TITLE}\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct_preds = 0\n",
        "    total_preds = 0\n",
        "    logdf_trn = pd.DataFrame(columns=['loss', 'outputs', 'predicts', 'label'])\n",
        "\n",
        "    # Training loop\n",
        "    for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\"):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        preds = (torch.sigmoid(outputs) > 0.5).float()\n",
        "        correct_preds += (preds == labels).all(dim=1).sum().item()\n",
        "        total_preds += preds.size(0)\n",
        "\n",
        "        ## print to csv\n",
        "        outputs_array = outputs.detach().cpu().numpy().round(2)\n",
        "        preds_array = preds.cpu().numpy()\n",
        "        labels_array = labels.cpu().numpy()\n",
        "\n",
        "        # loss 값을 64번 반복하여 각 row에 포함\n",
        "        loss_column = [loss.item()] * outputs_array.shape[0]\n",
        "\n",
        "        # 새로운 DataFrame 생성\n",
        "        new_rows = pd.DataFrame({\n",
        "            'loss': loss_column,\n",
        "            'outputs': list(outputs_array),\n",
        "            'predicts': list(preds_array),\n",
        "            'label': list(labels_array)\n",
        "        })\n",
        "        logdf_trn = pd.concat([logdf_trn, new_rows], ignore_index=True)\n",
        "    logdf_trn.to_csv(output_folder+ f'/log_{epoch+1}_train.csv', index=False)\n",
        "\n",
        "    train_loss = running_loss / len(train_loader)\n",
        "    train_accuracy = correct_preds / total_preds\n",
        "\n",
        "    model.eval()\n",
        "    valid_loss = 0.0\n",
        "    correct_preds = 0\n",
        "    total_preds = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    logdf_val = pd.DataFrame(columns=['loss', 'outputs', 'predicts', 'label'])\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(valid_loader, desc=f\"Validating Epoch {epoch+1}/{num_epochs}\", unit=\"batch\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            valid_loss += loss.item()\n",
        "\n",
        "            # Compute binary predictions\n",
        "            preds = (torch.sigmoid(outputs) > 0.5).float()\n",
        "            \"\"\"\n",
        "            # Check all-zero predictions row-wise\n",
        "            row_sums = preds.sum(dim=1)  # Sum predictions for each row\n",
        "            zero_rows = (row_sums == 0)  # Identify rows where all predictions are 0\n",
        "\n",
        "            # Handle all-zero rows\n",
        "            if zero_rows.any():  # If any row is all zeros\n",
        "                argmax_indices = outputs.argmax(dim=1)  # Get argmax index for each row\n",
        "                preds[zero_rows] = torch.zeros_like(preds[zero_rows])  # Reset all-zero rows to zeros\n",
        "                preds[zero_rows, argmax_indices[zero_rows]] = 1  # Set the argmax index to 1 for affected rows\n",
        "            \"\"\"\n",
        "\n",
        "            correct_preds += (preds == labels).all(dim=1).sum().item()\n",
        "            total_preds += preds.size(0)\n",
        "\n",
        "            all_preds.append(preds.cpu())\n",
        "            all_labels.append(labels.cpu())\n",
        "\n",
        "            ## print to csv\n",
        "            outputs_array = outputs.cpu().numpy().round(2)\n",
        "            preds_array = preds.cpu().numpy()\n",
        "            labels_array = labels.cpu().numpy()\n",
        "\n",
        "            # loss 값을 64번 반복하여 각 row에 포함\n",
        "            loss_column = [loss.item()] * outputs_array.shape[0]\n",
        "\n",
        "            # 새로운 DataFrame 생성\n",
        "            new_rows = pd.DataFrame({\n",
        "                'loss': loss_column,\n",
        "                'outputs': list(outputs_array),\n",
        "                'predicts': list(preds_array),\n",
        "                'label': list(labels_array)\n",
        "            })\n",
        "            logdf_val = pd.concat([logdf_val, new_rows], ignore_index=True)\n",
        "\n",
        "\n",
        "        valid_loss = valid_loss / len(valid_loader)\n",
        "        valid_accuracy = correct_preds / total_preds\n",
        "\n",
        "        all_preds = torch.cat(all_preds).numpy()\n",
        "        all_labels = torch.cat(all_labels).numpy()\n",
        "        f1 = f1_score(all_labels, all_preds, average='macro')\n",
        "\n",
        "\n",
        "\n",
        "        if f1 > best_valid_f1:\n",
        "            best_valid_f1 = f1\n",
        "            save_path = output_folder+f\"/resnet18_e{epoch+1}_{time.time()}.pth\"\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "            print(f\"Best model saved with F1: {f1:.4f}\")\n",
        "\n",
        "    logdf_val.to_csv(output_folder+ f'/log_{epoch+1}_valid.csv', index=False)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n",
        "    print(f\"Valid Loss: {valid_loss:.4f}, Valid Accuracy: {valid_accuracy:.4f}\")\n",
        "    print(f\"Validation F1 Score: {f1:.4f}\")\n",
        "    print(\"===============================\")\n",
        "    with open(output_folder+'/training_log.txt', 'a') as f:  # 'a' 모드로 파일에 추가 기록\n",
        "        f.write(f\"Epoch {epoch+1}/{num_epochs}\\n\")\n",
        "        f.write(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\\n\")\n",
        "        f.write(f\"Valid Loss: {valid_loss:.4f}, Valid Accuracy: {valid_accuracy:.4f}\\n\")\n",
        "        f.write(f\"Validation F1 Score: {f1:.4f}\\n\")\n",
        "        f.write(\"===============================\\n\")\n",
        "    #print(f\"Criterion Alpha:  {criterion.alpha}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "eWnXM1ZwNWq1",
        "outputId": "6819cc5d-c407-44d2-f1cb-36308e14951f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/training_az_nf_focal_classw2.zip'"
            ]
          },
          "execution_count": 209,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import shutil\n",
        "\n",
        "# 'folder_path' 폴더를 'archive_name.zip'으로 압축\n",
        "shutil.make_archive('training_az_nf_focal_classw2', 'zip', '/content/training_az_nf_focal_classw2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XAkMCF2WNXYI"
      },
      "outputs": [],
      "source": [
        "!cp training_az_nf_focal_classw2.zip /content/drive/MyDrive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2w8yJRaR-xJg"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xv8Jqd6O-swC",
        "outputId": "14279890-91e0-46c3-b25f-6dd8d899b40a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 105/105 [00:21<00:00,  4.93batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Results\n",
            "Test Loss: 0.6335, Test Accuracy: 0.1845\n",
            "Test F1 Score: 0.4089\n",
            "Test AUC Score: 0.7076\n",
            "\n",
            "Class-wise Accuracy:\n",
            "Class Atelectasis: 0.6795\n",
            "Class Consolidation: 0.8084\n",
            "Class Effusion: 0.7529\n",
            "Class Infiltration: 0.5986\n",
            "Class Mass: 0.8541\n",
            "Class Nodule: 0.8215\n",
            "Class Pneumothorax: 0.8715\n",
            "\n",
            "Class-wise AUC:\n",
            "Class Atelectasis: 0.6899\n",
            "Class Consolidation: 0.6160\n",
            "Class Effusion: 0.8099\n",
            "Class Infiltration: 0.6407\n",
            "Class Mass: 0.7510\n",
            "Class Nodule: 0.6822\n",
            "Class Pneumothorax: 0.7639\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "  Atelectasis       0.50      0.48      0.49      2153\n",
            "Consolidation       0.20      0.12      0.15       945\n",
            "     Effusion       0.69      0.63      0.66      2548\n",
            " Infiltration       0.58      0.58      0.58      3203\n",
            "         Mass       0.52      0.32      0.40       999\n",
            "       Nodule       0.38      0.22      0.28      1049\n",
            " Pneumothorax       0.66      0.20      0.30       950\n",
            "\n",
            "    micro avg       0.55      0.45      0.50     11847\n",
            "    macro avg       0.50      0.37      0.41     11847\n",
            " weighted avg       0.54      0.45      0.48     11847\n",
            "  samples avg       0.53      0.48      0.47     11847\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# --- Test Loop ---\n",
        "best_path = \"/content/training_az_nf_focal_classw2/resnet18_e9_1733932322.8122168.pth\"\n",
        "model = CustomResNet18(num_classes=num_classes).to(device)\n",
        "model.load_state_dict(torch.load(best_path))\n",
        "model.eval()\n",
        "\n",
        "test_loss = 0.0\n",
        "correct_preds = 0\n",
        "total_preds = 0\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "all_probs = []\n",
        "\n",
        "class_correct = [0] * num_classes\n",
        "class_total = [0] * num_classes\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in tqdm(test_loader, desc=\"Testing\", unit=\"batch\"):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        test_loss += loss.item()\n",
        "\n",
        "        preds = (torch.sigmoid(outputs) > 0.5).float()\n",
        "        correct_preds += (preds == labels).all(dim=1).sum().item()\n",
        "        total_preds += preds.size(0)\n",
        "\n",
        "        all_preds.append(preds.cpu())\n",
        "        all_labels.append(labels.cpu())\n",
        "\n",
        "        all_probs.append(torch.sigmoid(outputs).cpu())\n",
        "\n",
        "        for i in range(num_classes):\n",
        "            class_correct[i] += ((preds[:, i] == labels[:, i]).sum()).item()\n",
        "            class_total[i] += labels[:, i].size(0)\n",
        "\n",
        "test_loss = test_loss / len(test_loader)\n",
        "test_accuracy = correct_preds / total_preds\n",
        "\n",
        "all_preds = torch.cat(all_preds).numpy()\n",
        "all_labels = torch.cat(all_labels).numpy()\n",
        "all_probs = torch.cat(all_probs).numpy()\n",
        "\n",
        "# Macro-Averaged F1 Score\n",
        "test_f1 = f1_score(all_labels, all_preds, average='macro')\n",
        "\n",
        "# Multi-class AUC (One-vs-Rest)\n",
        "auc = roc_auc_score(all_labels, all_probs, average='macro', multi_class='ovr')\n",
        "\n",
        "# Class-wise AUC\n",
        "class_aucs = []\n",
        "for i in range(num_classes):\n",
        "    if np.sum(all_labels[:, i]) > 0:  # Only calculate if the class has positive samples\n",
        "        class_auc = roc_auc_score(all_labels[:, i], all_probs[:, i])\n",
        "    else:\n",
        "        class_auc = float('nan')  # Handle cases with no positive samples\n",
        "    class_aucs.append(class_auc)\n",
        "\n",
        "class_accuracy = [class_correct[i] / class_total[i] if class_total[i] > 0 else 0 for i in range(num_classes)]\n",
        "\n",
        "# Classification Report\n",
        "report = classification_report(all_labels, all_preds, target_names=class_names, zero_division=0)\n",
        "\n",
        "# Print Results\n",
        "print(\"\\nTest Results\")\n",
        "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"Test F1 Score: {test_f1:.4f}\")\n",
        "print(f\"Test AUC Score: {auc:.4f}\")\n",
        "\n",
        "print(\"\\nClass-wise Accuracy:\")\n",
        "for i, accuracy in enumerate(class_accuracy):\n",
        "    print(f\"Class {class_names[i]}: {accuracy:.4f}\")\n",
        "\n",
        "print(\"\\nClass-wise AUC:\")\n",
        "for i, class_auc in enumerate(class_aucs):\n",
        "    if np.isnan(class_auc):\n",
        "        print(f\"Class {class_names[i]}: N/A (No positive samples)\")\n",
        "    else:\n",
        "        print(f\"Class {class_names[i]}: {class_auc:.4f}\")\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(report)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzsN9s8D-qUE"
      },
      "source": [
        "## Post Processing, Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Wp2pKLfVlu5-",
        "outputId": "edbead2e-6a59-4c4d-d9b2-8e17fd19d6f7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>correct</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>False</th>\n",
              "      <td>5802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>True</th>\n",
              "      <td>2626</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "correct\n",
              "False    5802\n",
              "True     2626\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "v20 = pd.read_csv(\"training_az_nf_simple/log_20_valid.csv\")\n",
        "v20['correct'] = v20['predicts'] == v20['label']\n",
        "v20['correct'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 931
        },
        "id": "3knV7pZlmQmx",
        "outputId": "6a4ec188-31d6-4cfe-d90e-21443e305e5d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th>predicts</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>[0. 0. 0. 0. 0. 0. 0. 0. 1.]</th>\n",
              "      <th>[0. 0. 0. 0. 0. 0. 0. 0. 1.]</th>\n",
              "      <td>1993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>[0. 0. 0. 1. 0. 0. 0. 0. 0.]</th>\n",
              "      <th>[0. 0. 0. 1. 0. 0. 0. 0. 0.]</th>\n",
              "      <td>236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>[0. 0. 1. 0. 0. 0. 0. 0. 0.]</th>\n",
              "      <th>[0. 0. 1. 0. 0. 0. 0. 0. 0.]</th>\n",
              "      <td>154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>[1. 0. 0. 0. 0. 0. 0. 0. 0.]</th>\n",
              "      <th>[1. 0. 0. 0. 0. 0. 0. 0. 0.]</th>\n",
              "      <td>58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>[0. 0. 1. 1. 0. 0. 0. 0. 0.]</th>\n",
              "      <th>[0. 0. 1. 1. 0. 0. 0. 0. 0.]</th>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>[0. 0. 0. 0. 0. 0. 0. 1. 0.]</th>\n",
              "      <th>[0. 0. 0. 0. 0. 0. 0. 1. 0.]</th>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>[0. 0. 0. 0. 1. 0. 0. 0. 0.]</th>\n",
              "      <th>[0. 0. 0. 0. 1. 0. 0. 0. 0.]</th>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>[0. 0. 0. 0. 0. 1. 0. 0. 0.]</th>\n",
              "      <th>[0. 0. 0. 0. 0. 1. 0. 0. 0.]</th>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>[1. 0. 1. 0. 0. 0. 0. 0. 0.]</th>\n",
              "      <th>[1. 0. 1. 0. 0. 0. 0. 0. 0.]</th>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>[0. 0. 0. 1. 0. 1. 0. 0. 0.]</th>\n",
              "      <th>[0. 0. 0. 1. 0. 1. 0. 0. 0.]</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>[0. 0. 1. 0. 1. 0. 0. 0. 0.]</th>\n",
              "      <th>[0. 0. 1. 0. 1. 0. 0. 0. 0.]</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>[1. 0. 0. 1. 0. 0. 0. 0. 0.]</th>\n",
              "      <th>[1. 0. 0. 1. 0. 0. 0. 0. 0.]</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>[0. 0. 0. 0. 0. 0. 1. 0. 0.]</th>\n",
              "      <th>[0. 0. 0. 0. 0. 0. 1. 0. 0.]</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>[0. 0. 0. 0. 1. 1. 0. 0. 0.]</th>\n",
              "      <th>[0. 0. 0. 0. 1. 1. 0. 0. 0.]</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>[1. 0. 0. 0. 0. 0. 0. 1. 0.]</th>\n",
              "      <th>[1. 0. 0. 0. 0. 0. 0. 1. 0.]</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>[0. 0. 0. 1. 0. 0. 0. 1. 0.]</th>\n",
              "      <th>[0. 0. 0. 1. 0. 0. 0. 1. 0.]</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>[0. 1. 0. 1. 0. 0. 0. 0. 0.]</th>\n",
              "      <th>[0. 1. 0. 1. 0. 0. 0. 0. 0.]</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>[0. 0. 1. 0. 0. 0. 0. 1. 0.]</th>\n",
              "      <th>[0. 0. 1. 0. 0. 0. 0. 1. 0.]</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>[0. 1. 0. 0. 0. 0. 0. 0. 0.]</th>\n",
              "      <th>[0. 1. 0. 0. 0. 0. 0. 0. 0.]</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>[0. 1. 1. 0. 0. 0. 0. 0. 0.]</th>\n",
              "      <th>[0. 1. 1. 0. 0. 0. 0. 0. 0.]</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>[0. 0. 0. 1. 1. 0. 0. 0. 0.]</th>\n",
              "      <th>[0. 0. 0. 1. 1. 0. 0. 0. 0.]</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>[0. 0. 1. 0. 0. 1. 0. 0. 0.]</th>\n",
              "      <th>[0. 0. 1. 0. 0. 1. 0. 0. 0.]</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>[0. 0. 1. 1. 0. 1. 0. 0. 0.]</th>\n",
              "      <th>[0. 0. 1. 1. 0. 1. 0. 0. 0.]</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>[0. 1. 1. 1. 0. 0. 0. 0. 0.]</th>\n",
              "      <th>[0. 1. 1. 1. 0. 0. 0. 0. 0.]</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>[1. 0. 1. 0. 0. 0. 0. 1. 0.]</th>\n",
              "      <th>[1. 0. 1. 0. 0. 0. 0. 1. 0.]</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>[1. 0. 1. 1. 0. 0. 0. 0. 0.]</th>\n",
              "      <th>[1. 0. 1. 1. 0. 0. 0. 0. 0.]</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "label                         predicts                    \n",
              "[0. 0. 0. 0. 0. 0. 0. 0. 1.]  [0. 0. 0. 0. 0. 0. 0. 0. 1.]    1993\n",
              "[0. 0. 0. 1. 0. 0. 0. 0. 0.]  [0. 0. 0. 1. 0. 0. 0. 0. 0.]     236\n",
              "[0. 0. 1. 0. 0. 0. 0. 0. 0.]  [0. 0. 1. 0. 0. 0. 0. 0. 0.]     154\n",
              "[1. 0. 0. 0. 0. 0. 0. 0. 0.]  [1. 0. 0. 0. 0. 0. 0. 0. 0.]      58\n",
              "[0. 0. 1. 1. 0. 0. 0. 0. 0.]  [0. 0. 1. 1. 0. 0. 0. 0. 0.]      45\n",
              "[0. 0. 0. 0. 0. 0. 0. 1. 0.]  [0. 0. 0. 0. 0. 0. 0. 1. 0.]      34\n",
              "[0. 0. 0. 0. 1. 0. 0. 0. 0.]  [0. 0. 0. 0. 1. 0. 0. 0. 0.]      33\n",
              "[0. 0. 0. 0. 0. 1. 0. 0. 0.]  [0. 0. 0. 0. 0. 1. 0. 0. 0.]      21\n",
              "[1. 0. 1. 0. 0. 0. 0. 0. 0.]  [1. 0. 1. 0. 0. 0. 0. 0. 0.]      16\n",
              "[0. 0. 0. 1. 0. 1. 0. 0. 0.]  [0. 0. 0. 1. 0. 1. 0. 0. 0.]       5\n",
              "[0. 0. 1. 0. 1. 0. 0. 0. 0.]  [0. 0. 1. 0. 1. 0. 0. 0. 0.]       5\n",
              "[1. 0. 0. 1. 0. 0. 0. 0. 0.]  [1. 0. 0. 1. 0. 0. 0. 0. 0.]       4\n",
              "[0. 0. 0. 0. 0. 0. 1. 0. 0.]  [0. 0. 0. 0. 0. 0. 1. 0. 0.]       2\n",
              "[0. 0. 0. 0. 1. 1. 0. 0. 0.]  [0. 0. 0. 0. 1. 1. 0. 0. 0.]       2\n",
              "[1. 0. 0. 0. 0. 0. 0. 1. 0.]  [1. 0. 0. 0. 0. 0. 0. 1. 0.]       2\n",
              "[0. 0. 0. 1. 0. 0. 0. 1. 0.]  [0. 0. 0. 1. 0. 0. 0. 1. 0.]       2\n",
              "[0. 1. 0. 1. 0. 0. 0. 0. 0.]  [0. 1. 0. 1. 0. 0. 0. 0. 0.]       2\n",
              "[0. 0. 1. 0. 0. 0. 0. 1. 0.]  [0. 0. 1. 0. 0. 0. 0. 1. 0.]       2\n",
              "[0. 1. 0. 0. 0. 0. 0. 0. 0.]  [0. 1. 0. 0. 0. 0. 0. 0. 0.]       2\n",
              "[0. 1. 1. 0. 0. 0. 0. 0. 0.]  [0. 1. 1. 0. 0. 0. 0. 0. 0.]       2\n",
              "[0. 0. 0. 1. 1. 0. 0. 0. 0.]  [0. 0. 0. 1. 1. 0. 0. 0. 0.]       1\n",
              "[0. 0. 1. 0. 0. 1. 0. 0. 0.]  [0. 0. 1. 0. 0. 1. 0. 0. 0.]       1\n",
              "[0. 0. 1. 1. 0. 1. 0. 0. 0.]  [0. 0. 1. 1. 0. 1. 0. 0. 0.]       1\n",
              "[0. 1. 1. 1. 0. 0. 0. 0. 0.]  [0. 1. 1. 1. 0. 0. 0. 0. 0.]       1\n",
              "[1. 0. 1. 0. 0. 0. 0. 1. 0.]  [1. 0. 1. 0. 0. 0. 0. 1. 0.]       1\n",
              "[1. 0. 1. 1. 0. 0. 0. 0. 0.]  [1. 0. 1. 1. 0. 0. 0. 0. 0.]       1\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "v20right = v20[v20['correct'] == True]\n",
        "v20right[['label', 'predicts']].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "trjXI5lXl50l",
        "outputId": "6b4cd980-b4d3-41f0-979a-a45a893aebf2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th>predicts</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>[0. 0. 0. 0. 0. 0. 0. 0. 1.]</th>\n",
              "      <th>[0. 0. 0. 0. 0. 0. 0. 0. 0.]</th>\n",
              "      <td>708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>[0. 0. 0. 1. 0. 0. 0. 0. 0.]</th>\n",
              "      <th>[0. 0. 0. 0. 0. 0. 0. 0. 1.]</th>\n",
              "      <td>359</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>[0. 0. 0. 0. 0. 0. 0. 0. 1.]</th>\n",
              "      <th>[0. 0. 0. 1. 0. 0. 0. 0. 0.]</th>\n",
              "      <td>331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>[0. 0. 0. 1. 0. 0. 0. 0. 0.]</th>\n",
              "      <th>[0. 0. 0. 0. 0. 0. 0. 0. 0.]</th>\n",
              "      <td>206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>[0. 0. 0. 0. 0. 0. 0. 0. 1.]</th>\n",
              "      <th>[0. 0. 1. 0. 0. 0. 0. 0. 0.]</th>\n",
              "      <td>156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>[1. 1. 0. 0. 0. 1. 0. 0. 0.]</th>\n",
              "      <th>[1. 0. 1. 1. 0. 0. 0. 0. 0.]</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">[1. 1. 0. 0. 1. 0. 0. 0. 0.]</th>\n",
              "      <th>[0. 0. 0. 0. 0. 0. 0. 0. 0.]</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>[0. 0. 0. 0. 1. 0. 0. 0. 0.]</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">[1. 1. 0. 0. 0. 0. 0. 0. 0.]</th>\n",
              "      <th>[1. 0. 0. 0. 0. 0. 1. 0. 0.]</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>[1. 0. 0. 1. 0. 0. 0. 0. 0.]</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>796 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "label                         predicts                    \n",
              "[0. 0. 0. 0. 0. 0. 0. 0. 1.]  [0. 0. 0. 0. 0. 0. 0. 0. 0.]    708\n",
              "[0. 0. 0. 1. 0. 0. 0. 0. 0.]  [0. 0. 0. 0. 0. 0. 0. 0. 1.]    359\n",
              "[0. 0. 0. 0. 0. 0. 0. 0. 1.]  [0. 0. 0. 1. 0. 0. 0. 0. 0.]    331\n",
              "[0. 0. 0. 1. 0. 0. 0. 0. 0.]  [0. 0. 0. 0. 0. 0. 0. 0. 0.]    206\n",
              "[0. 0. 0. 0. 0. 0. 0. 0. 1.]  [0. 0. 1. 0. 0. 0. 0. 0. 0.]    156\n",
              "                                                             ... \n",
              "[1. 1. 0. 0. 0. 1. 0. 0. 0.]  [1. 0. 1. 1. 0. 0. 0. 0. 0.]      1\n",
              "[1. 1. 0. 0. 1. 0. 0. 0. 0.]  [0. 0. 0. 0. 0. 0. 0. 0. 0.]      1\n",
              "                              [0. 0. 0. 0. 1. 0. 0. 0. 0.]      1\n",
              "[1. 1. 0. 0. 0. 0. 0. 0. 0.]  [1. 0. 0. 0. 0. 0. 1. 0. 0.]      1\n",
              "                              [1. 0. 0. 1. 0. 0. 0. 0. 0.]      1\n",
              "Name: count, Length: 796, dtype: int64"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "v20wrong = v20[v20['correct'] == False]\n",
        "v20wrong[['label', 'predicts']].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "DSQi_dNXmk9-",
        "outputId": "34adbaa0-be74-4dbf-e4a3-8bfe2a9c234e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>correct</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>True</th>\n",
              "      <td>40986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>False</th>\n",
              "      <td>25831</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "correct\n",
              "True     40986\n",
              "False    25831\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t20 = pd.read_csv(\"training_az_nf_simple/log_20_train.csv\")\n",
        "t20['correct'] = t20['predicts'] == t20['label']\n",
        "t20['correct'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "5ogxW-PQmwOV",
        "outputId": "0727cb36-2d8b-4650-de17-0308e3f7a621"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th>predicts</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>[0. 0. 0. 0. 0. 0. 0. 0. 1.]</th>\n",
              "      <th>[0. 0. 0. 0. 0. 0. 0. 0. 1.]</th>\n",
              "      <td>24886</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>[0. 0. 0. 1. 0. 0. 0. 0. 0.]</th>\n",
              "      <th>[0. 0. 0. 1. 0. 0. 0. 0. 0.]</th>\n",
              "      <td>4971</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>[0. 0. 1. 0. 0. 0. 0. 0. 0.]</th>\n",
              "      <th>[0. 0. 1. 0. 0. 0. 0. 0. 0.]</th>\n",
              "      <td>2195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>[1. 0. 0. 0. 0. 0. 0. 0. 0.]</th>\n",
              "      <th>[1. 0. 0. 0. 0. 0. 0. 0. 0.]</th>\n",
              "      <td>1934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>[0. 0. 0. 0. 0. 0. 0. 1. 0.]</th>\n",
              "      <th>[0. 0. 0. 0. 0. 0. 0. 1. 0.]</th>\n",
              "      <td>1355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>[1. 0. 0. 1. 0. 0. 1. 0. 0.]</th>\n",
              "      <th>[1. 0. 0. 1. 0. 0. 1. 0. 0.]</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>[1. 0. 0. 1. 0. 1. 0. 0. 0.]</th>\n",
              "      <th>[1. 0. 0. 1. 0. 1. 0. 0. 0.]</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>[1. 0. 1. 0. 0. 1. 0. 0. 0.]</th>\n",
              "      <th>[1. 0. 1. 0. 0. 1. 0. 0. 0.]</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>[1. 1. 1. 0. 0. 1. 0. 0. 0.]</th>\n",
              "      <th>[1. 1. 1. 0. 0. 1. 0. 0. 0.]</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>[1. 1. 1. 0. 1. 1. 0. 0. 0.]</th>\n",
              "      <th>[1. 1. 1. 0. 1. 1. 0. 0. 0.]</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>86 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "label                         predicts                    \n",
              "[0. 0. 0. 0. 0. 0. 0. 0. 1.]  [0. 0. 0. 0. 0. 0. 0. 0. 1.]    24886\n",
              "[0. 0. 0. 1. 0. 0. 0. 0. 0.]  [0. 0. 0. 1. 0. 0. 0. 0. 0.]     4971\n",
              "[0. 0. 1. 0. 0. 0. 0. 0. 0.]  [0. 0. 1. 0. 0. 0. 0. 0. 0.]     2195\n",
              "[1. 0. 0. 0. 0. 0. 0. 0. 0.]  [1. 0. 0. 0. 0. 0. 0. 0. 0.]     1934\n",
              "[0. 0. 0. 0. 0. 0. 0. 1. 0.]  [0. 0. 0. 0. 0. 0. 0. 1. 0.]     1355\n",
              "                                                              ...  \n",
              "[1. 0. 0. 1. 0. 0. 1. 0. 0.]  [1. 0. 0. 1. 0. 0. 1. 0. 0.]        1\n",
              "[1. 0. 0. 1. 0. 1. 0. 0. 0.]  [1. 0. 0. 1. 0. 1. 0. 0. 0.]        1\n",
              "[1. 0. 1. 0. 0. 1. 0. 0. 0.]  [1. 0. 1. 0. 0. 1. 0. 0. 0.]        1\n",
              "[1. 1. 1. 0. 0. 1. 0. 0. 0.]  [1. 1. 1. 0. 0. 1. 0. 0. 0.]        1\n",
              "[1. 1. 1. 0. 1. 1. 0. 0. 0.]  [1. 1. 1. 0. 1. 1. 0. 0. 0.]        1\n",
              "Name: count, Length: 86, dtype: int64"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t20right = t20[t20['correct'] == True]\n",
        "t20right[['label', 'predicts']].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "a48VkrOcm1pO",
        "outputId": "23b9f871-2a8a-4c15-ce5a-354a34f5cec8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th>predicts</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>[0. 0. 0. 0. 0. 0. 0. 0. 1.]</th>\n",
              "      <th>[0. 0. 0. 0. 0. 0. 0. 0. 0.]</th>\n",
              "      <td>2885</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">[0. 0. 0. 1. 0. 0. 0. 0. 0.]</th>\n",
              "      <th>[0. 0. 0. 0. 0. 0. 0. 0. 0.]</th>\n",
              "      <td>1775</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>[0. 0. 0. 0. 0. 0. 0. 0. 1.]</th>\n",
              "      <td>901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>[1. 0. 0. 0. 0. 0. 0. 0. 0.]</th>\n",
              "      <th>[0. 0. 0. 0. 0. 0. 0. 0. 0.]</th>\n",
              "      <td>746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>[0. 0. 0. 0. 0. 1. 0. 0. 0.]</th>\n",
              "      <th>[0. 0. 0. 0. 0. 0. 0. 0. 0.]</th>\n",
              "      <td>670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>[1. 1. 1. 0. 1. 0. 0. 0. 0.]</th>\n",
              "      <th>[0. 1. 1. 1. 0. 0. 0. 0. 0.]</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>[0. 0. 1. 0. 1. 1. 1. 0. 0.]</th>\n",
              "      <th>[0. 0. 0. 0. 0. 1. 0. 0. 0.]</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">[0. 0. 0. 0. 0. 0. 0. 0. 1.]</th>\n",
              "      <th>[0. 0. 0. 0. 0. 0. 1. 1. 0.]</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>[0. 0. 0. 0. 0. 1. 1. 0. 0.]</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>[0. 0. 0. 0. 1. 0. 0. 1. 0.]</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1811 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "label                         predicts                    \n",
              "[0. 0. 0. 0. 0. 0. 0. 0. 1.]  [0. 0. 0. 0. 0. 0. 0. 0. 0.]    2885\n",
              "[0. 0. 0. 1. 0. 0. 0. 0. 0.]  [0. 0. 0. 0. 0. 0. 0. 0. 0.]    1775\n",
              "                              [0. 0. 0. 0. 0. 0. 0. 0. 1.]     901\n",
              "[1. 0. 0. 0. 0. 0. 0. 0. 0.]  [0. 0. 0. 0. 0. 0. 0. 0. 0.]     746\n",
              "[0. 0. 0. 0. 0. 1. 0. 0. 0.]  [0. 0. 0. 0. 0. 0. 0. 0. 0.]     670\n",
              "                                                              ... \n",
              "[1. 1. 1. 0. 1. 0. 0. 0. 0.]  [0. 1. 1. 1. 0. 0. 0. 0. 0.]       1\n",
              "[0. 0. 1. 0. 1. 1. 1. 0. 0.]  [0. 0. 0. 0. 0. 1. 0. 0. 0.]       1\n",
              "[0. 0. 0. 0. 0. 0. 0. 0. 1.]  [0. 0. 0. 0. 0. 0. 1. 1. 0.]       1\n",
              "                              [0. 0. 0. 0. 0. 1. 1. 0. 0.]       1\n",
              "                              [0. 0. 0. 0. 1. 0. 0. 1. 0.]       1\n",
              "Name: count, Length: 1811, dtype: int64"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t20wrong = t20[t20['correct'] == False]\n",
        "t20wrong[['label', 'predicts']].value_counts()\n",
        "#000000 을 전부 0000001로 강제하면 accuracy높아질지도..?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7KWuPe925Cn",
        "outputId": "cdc45a2b-3f11-4d99-a1bd-16e23778afe2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1, 2, 3, 4]\n"
          ]
        }
      ],
      "source": [
        "import ast\n",
        "\n",
        "s = '[1,2,3,4]'\n",
        "lst = ast.literal_eval(s)\n",
        "print(lst)  # [1, 2, 3, 4]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "collapsed": true,
        "id": "ijF-JsGE3ayW",
        "outputId": "8120f69b-b738-489e-de82-543aed5ca9c2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"v20\",\n  \"rows\": 8428,\n  \"fields\": [\n    {\n      \"column\": \"loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06195765911953106,\n        \"min\": 0.3355721533298492,\n        \"max\": 0.6561898589134216,\n        \"num_unique_values\": 132,\n        \"samples\": [\n          0.476635068655014,\n          0.4831573963165283,\n          0.4174405336380005\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"outputs\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8428,\n        \"samples\": [\n          \"[ -8.14 -11.09 -10.88  -7.56  -9.76  -7.32  -7.85 -13.09   6.21]\",\n          \"[-2.59 -4.28 -2.85 -2.56 -3.8  -5.01 -1.82 -7.63 -0.97]\",\n          \"[-2.47 -2.69  0.19  0.27 -6.85 -2.82 -5.19 -7.57 -4.74]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"predicts\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 69,\n        \"samples\": [\n          \"[1. 0. 1. 0. 1. 0. 0. 0. 0.]\",\n          \"[0. 0. 0. 0. 0. 0. 0. 0. 1.]\",\n          \"[0. 1. 0. 0. 0. 0. 0. 0. 1.]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 105,\n        \"samples\": [\n          \"[1. 0. 0. 0. 0. 0. 1. 1. 0.]\",\n          \"[0. 1. 0. 1. 0. 1. 0. 0. 0.]\",\n          \"[0. 0. 1. 1. 0. 1. 0. 0. 0.]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"correct\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false,\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label_list\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"predicts_list\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "v20"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-9dcf6a38-4b62-4a14-9b10-fe3887ca36bc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>outputs</th>\n",
              "      <th>predicts</th>\n",
              "      <th>label</th>\n",
              "      <th>correct</th>\n",
              "      <th>label_list</th>\n",
              "      <th>predicts_list</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.492546</td>\n",
              "      <td>[-13.35 -13.87 -12.45 -11.45 -15.38  -9.45 -13...</td>\n",
              "      <td>[0. 0. 0. 0. 0. 0. 0. 0. 1.]</td>\n",
              "      <td>[0. 0. 0. 0. 0. 0. 0. 0. 1.]</td>\n",
              "      <td>True</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.492546</td>\n",
              "      <td>[-7.6  -5.41 -5.1  -2.65 -5.76 -4.15 -5.09 -7....</td>\n",
              "      <td>[0. 0. 0. 0. 0. 0. 0. 0. 1.]</td>\n",
              "      <td>[0. 0. 0. 0. 0. 0. 0. 0. 1.]</td>\n",
              "      <td>True</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.492546</td>\n",
              "      <td>[-11.53  -9.95  -4.27  -5.17 -12.22  -6.33  -6...</td>\n",
              "      <td>[0. 0. 0. 0. 0. 0. 0. 0. 1.]</td>\n",
              "      <td>[0. 0. 0. 1. 0. 0. 0. 0. 0.]</td>\n",
              "      <td>False</td>\n",
              "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.492546</td>\n",
              "      <td>[ -9.81  -9.1   -6.82  -3.24  -7.43  -4.   -10...</td>\n",
              "      <td>[0. 0. 0. 0. 0. 0. 0. 0. 1.]</td>\n",
              "      <td>[0. 0. 0. 0. 0. 0. 0. 0. 1.]</td>\n",
              "      <td>True</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.492546</td>\n",
              "      <td>[-1.01 -3.09  3.36 -0.1  -2.65 -2.02 -1.2  -3....</td>\n",
              "      <td>[0. 0. 1. 0. 0. 0. 0. 0. 0.]</td>\n",
              "      <td>[0. 0. 1. 1. 1. 1. 0. 0. 0.]</td>\n",
              "      <td>False</td>\n",
              "      <td>[0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
              "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9dcf6a38-4b62-4a14-9b10-fe3887ca36bc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9dcf6a38-4b62-4a14-9b10-fe3887ca36bc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9dcf6a38-4b62-4a14-9b10-fe3887ca36bc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c19a28b5-a3b1-4970-92ae-c3c73b342f6a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c19a28b5-a3b1-4970-92ae-c3c73b342f6a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c19a28b5-a3b1-4970-92ae-c3c73b342f6a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "       loss                                            outputs  \\\n",
              "0  0.492546  [-13.35 -13.87 -12.45 -11.45 -15.38  -9.45 -13...   \n",
              "1  0.492546  [-7.6  -5.41 -5.1  -2.65 -5.76 -4.15 -5.09 -7....   \n",
              "2  0.492546  [-11.53  -9.95  -4.27  -5.17 -12.22  -6.33  -6...   \n",
              "3  0.492546  [ -9.81  -9.1   -6.82  -3.24  -7.43  -4.   -10...   \n",
              "4  0.492546  [-1.01 -3.09  3.36 -0.1  -2.65 -2.02 -1.2  -3....   \n",
              "\n",
              "                       predicts                         label  correct  \\\n",
              "0  [0. 0. 0. 0. 0. 0. 0. 0. 1.]  [0. 0. 0. 0. 0. 0. 0. 0. 1.]     True   \n",
              "1  [0. 0. 0. 0. 0. 0. 0. 0. 1.]  [0. 0. 0. 0. 0. 0. 0. 0. 1.]     True   \n",
              "2  [0. 0. 0. 0. 0. 0. 0. 0. 1.]  [0. 0. 0. 1. 0. 0. 0. 0. 0.]    False   \n",
              "3  [0. 0. 0. 0. 0. 0. 0. 0. 1.]  [0. 0. 0. 0. 0. 0. 0. 0. 1.]     True   \n",
              "4  [0. 0. 1. 0. 0. 0. 0. 0. 0.]  [0. 0. 1. 1. 1. 1. 0. 0. 0.]    False   \n",
              "\n",
              "                                      label_list  \\\n",
              "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]   \n",
              "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]   \n",
              "2  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
              "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]   \n",
              "4  [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0]   \n",
              "\n",
              "                                   predicts_list  \n",
              "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]  \n",
              "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]  \n",
              "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]  \n",
              "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]  \n",
              "4  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  "
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "v20['label_list'] = v20['label'].apply(lambda x: x.replace(\" \", \",\"))\n",
        "v20['predicts_list'] = v20['predicts'].apply(lambda x: x.replace(\" \", \",\"))\n",
        "\n",
        "v20['label_list'] = v20['label_list'].apply(lambda x: ast.literal_eval(x))\n",
        "v20['predicts_list'] = v20['predicts_list'].apply(lambda x: ast.literal_eval(x))\n",
        "v20.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "CUPrjpwl95dn",
        "outputId": "54a11f21-9218-4061-9910-d099449009c3"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"t20\",\n  \"rows\": 66817,\n  \"fields\": [\n    {\n      \"column\": \"loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.02365448627598925,\n        \"min\": 0.0876305103302002,\n        \"max\": 0.7904998660087585,\n        \"num_unique_values\": 1045,\n        \"samples\": [\n          0.1297607272863388,\n          0.1440620571374893,\n          0.1608878821134567\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"outputs\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 66817,\n        \"samples\": [\n          \"[-2.79 -2.28 -5.97 -0.5  -1.43 -0.38 -3.46 -5.13 -1.88]\",\n          \"[-2.3   0.37 -3.78  3.03 -1.34 -5.47 -7.74 -8.91 -8.62]\",\n          \"[-5.08 -7.39  5.14 -1.78 -7.75 -4.11 -5.35 -1.01 -6.94]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"predicts\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 126,\n        \"samples\": [\n          \"[1. 0. 0. 0. 0. 1. 0. 1. 0.]\",\n          \"[0. 0. 0. 0. 1. 0. 1. 0. 0.]\",\n          \"[0. 1. 0. 0. 1. 0. 0. 1. 0.]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 118,\n        \"samples\": [\n          \"[1. 0. 0. 0. 1. 1. 0. 0. 0.]\",\n          \"[0. 1. 0. 0. 1. 1. 0. 0. 0.]\",\n          \"[1. 0. 1. 0. 0. 0. 0. 0. 0.]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"correct\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false,\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label_list\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"predicts_list\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "t20"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-cf57eb2d-1726-471c-88a1-c8e82d604ffd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>outputs</th>\n",
              "      <th>predicts</th>\n",
              "      <th>label</th>\n",
              "      <th>correct</th>\n",
              "      <th>label_list</th>\n",
              "      <th>predicts_list</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.102575</td>\n",
              "      <td>[-5.   -7.47 -7.15 -4.09 -4.76 -5.41 -6.19 -9....</td>\n",
              "      <td>[0. 0. 0. 0. 0. 0. 0. 0. 1.]</td>\n",
              "      <td>[0. 0. 0. 0. 0. 0. 0. 0. 1.]</td>\n",
              "      <td>True</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.102575</td>\n",
              "      <td>[-4.23 -3.33 -2.1   0.23 -5.29 -2.82 -5.42 -5....</td>\n",
              "      <td>[0. 0. 0. 1. 0. 0. 0. 0. 0.]</td>\n",
              "      <td>[0. 0. 1. 0. 0. 0. 0. 0. 0.]</td>\n",
              "      <td>False</td>\n",
              "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
              "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.102575</td>\n",
              "      <td>[-5.78 -6.39 -8.4  -5.59 -8.06 -8.22 -9.58 -9....</td>\n",
              "      <td>[0. 0. 0. 0. 0. 0. 0. 0. 1.]</td>\n",
              "      <td>[0. 0. 0. 0. 0. 0. 0. 0. 1.]</td>\n",
              "      <td>True</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.102575</td>\n",
              "      <td>[ -5.73  -7.21  -7.91  -6.    -6.39  -5.67 -10...</td>\n",
              "      <td>[0. 0. 0. 0. 0. 0. 0. 0. 1.]</td>\n",
              "      <td>[0. 0. 0. 0. 0. 0. 0. 0. 1.]</td>\n",
              "      <td>True</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.102575</td>\n",
              "      <td>[ -8.94  -7.1   -7.99  -3.44 -10.22  -8.15 -10...</td>\n",
              "      <td>[0. 0. 0. 0. 0. 0. 0. 0. 1.]</td>\n",
              "      <td>[0. 0. 0. 0. 0. 0. 0. 0. 1.]</td>\n",
              "      <td>True</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cf57eb2d-1726-471c-88a1-c8e82d604ffd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cf57eb2d-1726-471c-88a1-c8e82d604ffd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cf57eb2d-1726-471c-88a1-c8e82d604ffd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-44241988-6c5c-48c5-9f04-b29c80526ea7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-44241988-6c5c-48c5-9f04-b29c80526ea7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-44241988-6c5c-48c5-9f04-b29c80526ea7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "       loss                                            outputs  \\\n",
              "0  0.102575  [-5.   -7.47 -7.15 -4.09 -4.76 -5.41 -6.19 -9....   \n",
              "1  0.102575  [-4.23 -3.33 -2.1   0.23 -5.29 -2.82 -5.42 -5....   \n",
              "2  0.102575  [-5.78 -6.39 -8.4  -5.59 -8.06 -8.22 -9.58 -9....   \n",
              "3  0.102575  [ -5.73  -7.21  -7.91  -6.    -6.39  -5.67 -10...   \n",
              "4  0.102575  [ -8.94  -7.1   -7.99  -3.44 -10.22  -8.15 -10...   \n",
              "\n",
              "                       predicts                         label  correct  \\\n",
              "0  [0. 0. 0. 0. 0. 0. 0. 0. 1.]  [0. 0. 0. 0. 0. 0. 0. 0. 1.]     True   \n",
              "1  [0. 0. 0. 1. 0. 0. 0. 0. 0.]  [0. 0. 1. 0. 0. 0. 0. 0. 0.]    False   \n",
              "2  [0. 0. 0. 0. 0. 0. 0. 0. 1.]  [0. 0. 0. 0. 0. 0. 0. 0. 1.]     True   \n",
              "3  [0. 0. 0. 0. 0. 0. 0. 0. 1.]  [0. 0. 0. 0. 0. 0. 0. 0. 1.]     True   \n",
              "4  [0. 0. 0. 0. 0. 0. 0. 0. 1.]  [0. 0. 0. 0. 0. 0. 0. 0. 1.]     True   \n",
              "\n",
              "                                      label_list  \\\n",
              "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]   \n",
              "1  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
              "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]   \n",
              "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]   \n",
              "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]   \n",
              "\n",
              "                                   predicts_list  \n",
              "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]  \n",
              "1  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
              "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]  \n",
              "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]  \n",
              "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]  "
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t20['label_list'] = t20['label'].apply(lambda x: x.replace(\" \", \",\"))\n",
        "t20['predicts_list'] = t20['predicts'].apply(lambda x: x.replace(\" \", \",\"))\n",
        "\n",
        "t20['label_list'] = t20['label_list'].apply(lambda x: ast.literal_eval(x))\n",
        "t20['predicts_list'] = t20['predicts_list'].apply(lambda x: ast.literal_eval(x))\n",
        "t20.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdP8I3Qo2kNb",
        "outputId": "7787923d-a689-4ab3-ffdf-492ea3cded0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Multiclass AUC (ROC): 0.8273129536636494\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "y_true = np.array(list(t20['label_list'].values))\n",
        "y_score = np.array(t20['predicts_list'].to_list())\n",
        "\n",
        "# 다중 클래스 ROC-AUC 계산\n",
        "# multi_class='ovr' 또는 'ovo' 선택 가능. average='weighted' or 'macro' 등으로 조정 가능.\n",
        "auc = roc_auc_score(y_true, y_score, multi_class='ovr', average='weighted')\n",
        "\n",
        "print(\"Multiclass AUC (ROC):\", auc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kTaeYrTt3-Yt"
      },
      "outputs": [],
      "source": [
        "n_classes = 7\n",
        "\n",
        "# 각 클래스별 ROC, AUC 계산\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "\n",
        "for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_true[:, i], y_score[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "# micro-average ROC 곡선 (모든 클래스의 TP, FP를 누적)\n",
        "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_true.ravel(), y_score.ravel())\n",
        "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "\n",
        "# macro-average ROC 계산\n",
        "# 모든 클래스 ROC AUC의 단순 평균\n",
        "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
        "mean_tpr = np.zeros_like(all_fpr)\n",
        "for i in range(n_classes):\n",
        "    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
        "mean_tpr /= n_classes\n",
        "\n",
        "fpr[\"macro\"] = all_fpr\n",
        "tpr[\"macro\"] = mean_tpr\n",
        "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
        "\n",
        "# ROC 커브 그리기\n",
        "plt.figure()\n",
        "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
        "         label=f'micro-average ROC curve (AUC = {roc_auc[\"micro\"]:.2f})',\n",
        "         color='deeppink', linestyle=':', linewidth=4)\n",
        "\n",
        "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
        "         label=f'macro-average ROC curve (AUC = {roc_auc[\"macro\"]:.2f})',\n",
        "         color='navy', linestyle=':', linewidth=4)\n",
        "\n",
        "colors = ['aqua', 'darkorange', 'cornflowerblue']*3\n",
        "for i, color in zip(range(n_classes), colors):\n",
        "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
        "             label=f'ROC curve of class {i} (AUC = {roc_auc[i]:.2f})')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw=2)  # 무작위 분류 기준선\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Multiclass ROC')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMdR6SKaI3QR"
      },
      "source": [
        "## Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "PlGhJelFI55R",
        "outputId": "938a9a79-ac29-49ce-8690-9c63bf19087c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.1.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.14.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.36)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.6)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.2)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.8-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
            "Downloading optuna-4.1.0-py3-none-any.whl (364 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m364.4/364.4 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.14.0-py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.5/233.5 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading Mako-1.3.8-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.8 alembic-1.14.0 colorlog-6.9.0 optuna-4.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OSwGnQeLJyiB"
      },
      "outputs": [],
      "source": [
        "class ForcedBLL_simple(nn.Module):\n",
        "    def __init__(self, reduction='mean', initial_alpha=0.1, initial_beta=0.1):\n",
        "        super(ForcedBLL_simple, self).__init__()\n",
        "        self.bce_loss = nn.BCEWithLogitsLoss(reduction=reduction)\n",
        "        self.initial_alpha = initial_alpha\n",
        "        self.initial_beta = initial_beta\n",
        "\n",
        "    def forward(self, logits, targets):\n",
        "\n",
        "        ## BCEWithLogitsLoss\n",
        "        bce_loss = self.bce_loss(logits, targets)\n",
        "\n",
        "\n",
        "        ## class probabilities\n",
        "        probs = torch.sigmoid(logits)\n",
        "\n",
        "        ## All-Zero penalty\n",
        "        \"\"\"\n",
        "        # Regularization term: encourage at least one class to be close to 1 for each sample\n",
        "        max_probs = torch.max(probs, dim=1).values  # Max probability for each sample\n",
        "        reg_loss =  1 - max_probs  # Regularization term encourages max_probs to be close to 1\n",
        "        \"\"\"\n",
        "        zero_predictions = (probs.sum(dim=1) == 0).float()  # Rows where sum is 0\n",
        "        zero_penalty = zero_predictions.sum()  # Count rows with all zeros\n",
        "\n",
        "\n",
        "        ## Exclusive No Finding penalty\n",
        "        last_label_probs = probs[:, -1]  # Last column (last predicted label)\n",
        "        preceding_probs = probs[:, :-1]  # All columns except the last one\n",
        "\n",
        "        # Penalize if preceding values are not close to 0 when last_label is close to 1\n",
        "        penalty = torch.sum(preceding_probs * last_label_probs.unsqueeze(1))\n",
        "\n",
        "\n",
        "        # Combine BCE loss with the regularization term\n",
        "        total_loss = bce_loss + self.initial_alpha * zero_penalty / logits.size(0) + self.initial_beta * penalty / logits.size(0)\n",
        "\n",
        "        return total_loss\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class ForcedBLL_weighted(nn.Module):\n",
        "    def __init__(self, reduction='mean', initial_alpha=0.1, initial_beta=0.1, class_weights=class_weights):\n",
        "        super(ForcedBLL_weighted, self).__init__()\n",
        "        self.bce_loss = nn.BCEWithLogitsLoss(reduction=reduction, weight=torch.tensor(class_weights))\n",
        "        self.initial_alpha = initial_alpha\n",
        "        self.initial_beta = initial_beta\n",
        "\n",
        "    def forward(self, logits, targets):\n",
        "\n",
        "        ## BCEWithLogitsLoss\n",
        "        bce_loss = self.bce_loss(logits, targets)\n",
        "\n",
        "\n",
        "        ## class probabilities\n",
        "        probs = torch.sigmoid(logits)\n",
        "\n",
        "        ## All-Zero penalty\n",
        "        \"\"\"\n",
        "        # Regularization term: encourage at least one class to be close to 1 for each sample\n",
        "        max_probs = torch.max(probs, dim=1).values  # Max probability for each sample\n",
        "        reg_loss =  1 - max_probs  # Regularization term encourages max_probs to be close to 1\n",
        "        \"\"\"\n",
        "        zero_predictions = (probs.sum(dim=1) == 0).float()  # Rows where sum is 0\n",
        "        zero_penalty = zero_predictions.sum()  # Count rows with all zeros\n",
        "\n",
        "\n",
        "        ## Exclusive No Finding penalty\n",
        "        last_label_probs = probs[:, -1]  # Last column (last predicted label)\n",
        "        preceding_probs = probs[:, :-1]  # All columns except the last one\n",
        "\n",
        "        # Penalize if preceding values are not close to 0 when last_label is close to 1\n",
        "        penalty = torch.sum(preceding_probs * last_label_probs.unsqueeze(1))\n",
        "\n",
        "\n",
        "        # Combine BCE loss with the regularization term\n",
        "        total_loss = bce_loss + self.initial_alpha * zero_penalty / logits.size(0) + self.initial_beta * penalty / logits.size(0)\n",
        "\n",
        "        return total_loss\n",
        "\n",
        "class ForcedBLL_focal(nn.Module):\n",
        "    def __init__(self, reduction='mean', initial_alpha=0.1, initial_beta=0.1, gamma_neg=4, gamma_pos=1):\n",
        "        super(ForcedBLL_focal, self).__init__()\n",
        "        self.bce_loss = nn.BCEWithLogitsLoss(reduction=reduction)\n",
        "        self.initial_alpha = initial_alpha\n",
        "        self.initial_beta = initial_beta\n",
        "        self.mse_loss = nn.MSELoss()\n",
        "        self.gamma_neg = gamma_neg\n",
        "        self.gamma_pos = gamma_pos\n",
        "\n",
        "    def forward(self, logits, targets):\n",
        "\n",
        "        ## BCEWithLogitsLoss\n",
        "        bce_loss = self.bce_loss(logits, targets)\n",
        "\n",
        "\n",
        "        ## class probabilities\n",
        "        probs = torch.sigmoid(logits)\n",
        "\n",
        "        ## Focal asymmetric Loss\n",
        "        p_t = probs * targets + (1 - probs) * (1 - targets)   # 맞은 거의 맞은 확률 + 틀린 거의 틀린 확률\n",
        "        gamma = self.gamma_pos * targets + self.gamma_neg * (1 - targets) #\n",
        "        #gamma = 2\n",
        "        focal_weight = torch.mean((1 - p_t).pow(gamma))\n",
        "\n",
        "\n",
        "\n",
        "        ## All-Zero penalty\n",
        "        \"\"\"\n",
        "        # Regularization term: encourage at least one class to be close to 1 for each sample\n",
        "        max_probs = torch.max(probs, dim=1).values  # Max probability for each sample\n",
        "        reg_loss =  1 - max_probs  # Regularization term encourages max_probs to be close to 1\n",
        "        \"\"\"\n",
        "        zero_predictions = (probs.sum(dim=1) == 0).float()  # Rows where sum is 0\n",
        "        zero_penalty = zero_predictions.sum()  # Count rows with all zeros\n",
        "\n",
        "\n",
        "        ## Exclusive No Finding penalty\n",
        "        last_label_probs = probs[:, -1]  # Last column (last predicted label)\n",
        "        preceding_probs = probs[:, :-1]  # All columns except the last one\n",
        "\n",
        "        # Penalize if preceding values are not close to 0 when last_label is close to 1\n",
        "        penalty = torch.sum(preceding_probs * last_label_probs.unsqueeze(1))\n",
        "\n",
        "\n",
        "        # Combine BCE loss with the regularization term\n",
        "        total_loss = focal_weight * bce_loss + self.initial_alpha * zero_penalty / logits.size(0) + self.initial_beta * penalty / logits.size(0)\n",
        "\n",
        "        return total_loss\n",
        "\n",
        "\n",
        "class ForcedBLL_weightedfocal(nn.Module):\n",
        "    def __init__(self, reduction='mean', initial_alpha=0.1, initial_beta=0.1, gamma_neg=4, gamma_pos=1, class_weights=class_weights):\n",
        "        super(ForcedBLL_weightedfocal, self).__init__()\n",
        "        self.bce_loss = nn.BCEWithLogitsLoss(reduction=reduction, weight=torch.tensor(class_weights))\n",
        "        self.initial_alpha = initial_alpha\n",
        "        self.initial_beta = initial_beta\n",
        "        self.mse_loss = nn.MSELoss()\n",
        "        self.gamma_neg = gamma_neg\n",
        "        self.gamma_pos = gamma_pos\n",
        "\n",
        "    def forward(self, logits, targets):\n",
        "\n",
        "        ## BCEWithLogitsLoss\n",
        "        bce_loss = self.bce_loss(logits, targets)\n",
        "\n",
        "\n",
        "        ## class probabilities\n",
        "        probs = torch.sigmoid(logits)\n",
        "\n",
        "\n",
        "        ## Focal asymmetric Loss\n",
        "        p_t = probs * targets + (1 - probs) * (1 - targets)   # 맞은 거의 맞은 확률 + 틀린 거의 틀린 확률\n",
        "        gamma = self.gamma_pos * targets + self.gamma_neg * (1 - targets)\n",
        "        focal_weight = torch.mean((1 - p_t).pow(gamma))\n",
        "\n",
        "\n",
        "\n",
        "        ## All-Zero penalty\n",
        "        \"\"\"\n",
        "        # Regularization term: encourage at least one class to be close to 1 for each sample\n",
        "        max_probs = torch.max(probs, dim=1).values  # Max probability for each sample\n",
        "        reg_loss =  1 - max_probs  # Regularization term encourages max_probs to be close to 1\n",
        "        \"\"\"\n",
        "        zero_predictions = (probs.sum(dim=1) == 0).float()  # Rows where sum is 0\n",
        "        zero_penalty = zero_predictions.sum()  # Count rows with all zeros\n",
        "\n",
        "\n",
        "        ## Exclusive No Finding penalty\n",
        "        last_label_probs = probs[:, -1]  # Last column (last predicted label)\n",
        "        preceding_probs = probs[:, :-1]  # All columns except the last one\n",
        "\n",
        "        # Penalize if preceding values are not close to 0 when last_label is close to 1\n",
        "        penalty = torch.sum(preceding_probs * last_label_probs.unsqueeze(1))\n",
        "\n",
        "\n",
        "        # Combine BCE loss with the regularization term\n",
        "        total_loss = 0.5 * focal_weight * bce_loss + self.initial_alpha * zero_penalty / logits.size(0) + self.initial_beta * penalty / logits.size(0)\n",
        "\n",
        "        return total_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTODSDANJAn5",
        "outputId": "3a77dd86-a50e-4a90-a58c-735ba59e19ed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 216,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = CustomResNet18(num_classes=num_classes).to(device)\n",
        "best_path = \"/content/training_az_nf_focal/resnet18_e9_1733642727.2667074.pth\"\n",
        "model.load_state_dict(torch.load(save_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWn0gQfFI9i6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "import optuna\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torch.utils.data import DataLoader\n",
        "import sys\n",
        "\n",
        "# Define the objective function\n",
        "def objective(trial):\n",
        "    # Suggest hyperparameters\n",
        "    optimizer_name = trial.suggest_categorical('optimizer', ['Adam', 'SGD'])\n",
        "    lr = trial.suggest_float('lr', 1e-5, 1e-1, log=True)\n",
        "    batch_size = trial.suggest_int('batch_size', 16, 128, log=True)\n",
        "    loss_fn_name = trial.suggest_categorical('loss_fn', ['CrossEntropy', 'ForcedBLL_simple', 'ForcedBLL_weighted', 'ForcedBLL_focal', 'ForcedBLL_weightedfocal' ])\n",
        "    scheduler_step_size = trial.suggest_int('scheduler_step_size', 1, 10)\n",
        "    scheduler_gamma = trial.suggest_float('scheduler_gamma', 0.1, 0.9)\n",
        "\n",
        "    # Data loading and preprocessing\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "\n",
        "    train_dataset = CXR14dataset(img_dirs=img_dirs, df=train_df)\n",
        "    valid_dataset = CXR14dataset(img_dirs=img_dirs, df=valid_df)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_cores, pin_memory=True, persistent_workers=True)\n",
        "    valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=num_cores, pin_memory=True, persistent_workers=True)\n",
        "\n",
        "\n",
        "    # Model initialization\n",
        "    model = CustomResNet18(num_classes=num_classes).to(device)\n",
        "\n",
        "    # Loss function\n",
        "    if loss_fn_name == 'CrossEntropy':\n",
        "        criterion = nn.BCEWithLogitsLoss()\n",
        "    elif loss_fn_name == 'ForcedBLL_simple':\n",
        "        criterion = ForcedBLL_simple()\n",
        "    elif loss_fn_name == 'ForcedBLL_weighted':\n",
        "        criterion = ForcedBLL_weighted()\n",
        "    elif loss_fn_name == 'ForcedBLL_focal':\n",
        "        criterion = ForcedBLL_focal()\n",
        "    elif loss_fn_name == 'ForcedBLL_weightedfocal':\n",
        "        criterion = ForcedBLL_weightedfocal()\n",
        "    criterion = criterion.to(device)\n",
        "\n",
        "    # Optimizer\n",
        "    if optimizer_name == 'Adam':\n",
        "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    else:\n",
        "        optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "\n",
        "    # Learning rate scheduler\n",
        "    scheduler = StepLR(optimizer, step_size=scheduler_step_size, gamma=scheduler_gamma)\n",
        "\n",
        "    # Training loop\n",
        "    model.train()\n",
        "    for epoch in range(10):  # Number of epochs\n",
        "        print(\"epoch: \", epoch+1)\n",
        "        for data, target in tqdm(train_loader, file=sys.stdout):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    # Validation performance (use your validation dataset here)\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for data, target in valid_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            val_loss += loss.item()\n",
        "    val_loss /= len(valid_loader)\n",
        "\n",
        "    return val_loss\n",
        "\n",
        "# Create a study and optimize\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=50, show_progress_bar=False)\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print('Best trial:')\n",
        "trial = study.best_trial\n",
        "print(f'  Value: {trial.value}')\n",
        "print('  Params:')\n",
        "for key, value in trial.params.items():\n",
        "    print(f'    {key}: {value}')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}